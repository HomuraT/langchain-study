#!/usr/bin/env python3
"""
Pydantic BaseModelæµ‹è¯•è¿è¡Œå™¨

è¿è¡Œæ‰€æœ‰Pydantic BaseModelæ„é€ æ–¹å¼æµ‹è¯•ï¼Œå¹¶æä¾›è¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š
"""

import sys
import unittest
import time
from typing import List, Dict, Any
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from unitests.test_pydantic_base_model.test_basemodel_construction import TestPydanticBaseModelConstruction
from unitests.test_pydantic_base_model.test_advanced_construction import TestAdvancedPydanticConstruction


class PydanticTestRunner:
    """Pydanticæµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self):
        self.test_suites = {
            'basic': TestPydanticBaseModelConstruction,
            'advanced': TestAdvancedPydanticConstruction
        }
        self.results = {}
    
    def run_basic_tests(self) -> unittest.TestResult:
        """è¿è¡ŒåŸºæœ¬æ„é€ æ–¹å¼æµ‹è¯•"""
        print("\n" + "="*60)
        print("ğŸ”§ è¿è¡ŒåŸºæœ¬Pydantic BaseModelæ„é€ æ–¹å¼æµ‹è¯•")
        print("="*60)
        
        loader = unittest.TestLoader()
        suite = loader.loadTestsFromTestCase(TestPydanticBaseModelConstruction)
        runner = unittest.TextTestRunner(verbosity=2, stream=sys.stdout)
        
        start_time = time.time()
        result = runner.run(suite)
        end_time = time.time()
        
        self.results['basic'] = {
            'result': result,
            'duration': end_time - start_time,
            'tests_run': result.testsRun,
            'failures': len(result.failures),
            'errors': len(result.errors),
            'success_rate': (result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100
        }
        
        return result
    
    def run_advanced_tests(self) -> unittest.TestResult:
        """è¿è¡Œé«˜çº§æ„é€ æ–¹å¼æµ‹è¯•"""
        print("\n" + "="*60)
        print("ğŸš€ è¿è¡Œé«˜çº§Pydantic BaseModelæ„é€ æ–¹å¼æµ‹è¯•")
        print("="*60)
        
        loader = unittest.TestLoader()
        suite = loader.loadTestsFromTestCase(TestAdvancedPydanticConstruction)
        runner = unittest.TextTestRunner(verbosity=2, stream=sys.stdout)
        
        start_time = time.time()
        result = runner.run(suite)
        end_time = time.time()
        
        self.results['advanced'] = {
            'result': result,
            'duration': end_time - start_time,
            'tests_run': result.testsRun,
            'failures': len(result.failures),
            'errors': len(result.errors),
            'success_rate': (result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100
        }
        
        return result
    
    def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸŒŸ å¼€å§‹è¿è¡Œå®Œæ•´çš„Pydantic BaseModelæ„é€ æ–¹å¼æµ‹è¯•å¥—ä»¶")
        print("æµ‹è¯•åŒ…å«ï¼šåŸºæœ¬æ„é€ æ–¹å¼ + é«˜çº§æ„é€ æ–¹å¼")
        print("é¢„è®¡è¿è¡Œæ—¶é—´ï¼š30-60ç§’")
        
        overall_start = time.time()
        
        # è¿è¡ŒåŸºæœ¬æµ‹è¯•
        basic_result = self.run_basic_tests()
        
        # è¿è¡Œé«˜çº§æµ‹è¯•
        advanced_result = self.run_advanced_tests()
        
        overall_end = time.time()
        
        # æ±‡æ€»ç»“æœ
        summary = self._generate_summary(overall_end - overall_start)
        self._print_summary(summary)
        
        return summary
    
    def run_specific_tests(self, test_names: List[str]) -> Dict[str, Any]:
        """è¿è¡ŒæŒ‡å®šçš„æµ‹è¯•"""
        print(f"\nğŸ¯ è¿è¡ŒæŒ‡å®šæµ‹è¯•: {', '.join(test_names)}")
        
        overall_start = time.time()
        
        for test_name in test_names:
            if test_name == 'basic':
                self.run_basic_tests()
            elif test_name == 'advanced':
                self.run_advanced_tests()
            else:
                print(f"âš ï¸ æœªçŸ¥çš„æµ‹è¯•ç±»å‹: {test_name}")
        
        overall_end = time.time()
        summary = self._generate_summary(overall_end - overall_start)
        self._print_summary(summary)
        
        return summary
    
    def _generate_summary(self, total_duration: float) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æ‘˜è¦"""
        summary = {
            'total_duration': total_duration,
            'total_tests': 0,
            'total_failures': 0,
            'total_errors': 0,
            'overall_success_rate': 0,
            'test_categories': {}
        }
        
        for category, result_data in self.results.items():
            summary['total_tests'] += result_data['tests_run']
            summary['total_failures'] += result_data['failures']
            summary['total_errors'] += result_data['errors']
            summary['test_categories'][category] = result_data
        
        if summary['total_tests'] > 0:
            successful_tests = summary['total_tests'] - summary['total_failures'] - summary['total_errors']
            summary['overall_success_rate'] = successful_tests / summary['total_tests'] * 100
        
        return summary
    
    def _print_summary(self, summary: Dict[str, Any]) -> None:
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦")
        print("="*60)
        
        print(f"â±ï¸  æ€»è¿è¡Œæ—¶é—´: {summary['total_duration']:.2f}ç§’")
        print(f"ğŸ§ª æ€»æµ‹è¯•æ•°é‡: {summary['total_tests']}")
        print(f"âœ… æˆåŠŸç‡: {summary['overall_success_rate']:.1f}%")
        print(f"âŒ å¤±è´¥æ•°é‡: {summary['total_failures']}")
        print(f"ğŸ’¥ é”™è¯¯æ•°é‡: {summary['total_errors']}")
        
        print("\nğŸ“‹ åˆ†ç±»è¯¦æƒ…:")
        for category, data in summary['test_categories'].items():
            status_icon = "âœ…" if data['failures'] == 0 and data['errors'] == 0 else "âŒ"
            print(f"  {status_icon} {category.upper()}:")
            print(f"     - æµ‹è¯•æ•°é‡: {data['tests_run']}")
            print(f"     - è¿è¡Œæ—¶é—´: {data['duration']:.2f}ç§’")
            print(f"     - æˆåŠŸç‡: {data['success_rate']:.1f}%")
            if data['failures'] > 0:
                print(f"     - å¤±è´¥: {data['failures']}")
            if data['errors'] > 0:
                print(f"     - é”™è¯¯: {data['errors']}")
        
        print("\n" + "="*60)
        
        if summary['total_failures'] == 0 and summary['total_errors'] == 0:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Pydantic BaseModelæ„é€ æ–¹å¼æµ‹è¯•å®Œæˆã€‚")
        else:
            print("âš ï¸ å­˜åœ¨æµ‹è¯•å¤±è´¥æˆ–é”™è¯¯ï¼Œè¯·æ£€æŸ¥ä¸Šé¢çš„è¯¦ç»†è¾“å‡ºã€‚")
        
        print("="*60)
    
    def list_available_tests(self) -> None:
        """åˆ—å‡ºå¯ç”¨çš„æµ‹è¯•"""
        print("\nğŸ“ å¯ç”¨çš„æµ‹è¯•ç±»åˆ«:")
        print("- basic: åŸºæœ¬Pydantic BaseModelæ„é€ æ–¹å¼æµ‹è¯•")
        print("  * åŸºæœ¬åˆ›å»ºæ–¹å¼")
        print("  * Fieldå­—æ®µå®šä¹‰")
        print("  * æ•°æ®éªŒè¯å™¨")
        print("  * åµŒå¥—æ¨¡å‹")
        print("  * æ³›å‹æ¨¡å‹")
        print("  * æšä¸¾ç±»å‹")
        print("  * Unionå’ŒOptionalç±»å‹")
        print("  * è‡ªå®šä¹‰ç±»å‹")
        print("  * åˆ«åå’Œåºåˆ—åŒ–")
        print("  * é…ç½®ç±»")
        print("  * ç»§æ‰¿å’Œæ··åˆ")
        print("  * å·¥å‚æ–¹æ³•å’ŒåŠ¨æ€åˆ›å»º")
        print("  * æ¡ä»¶å­—æ®µ")
        print("  * Settingsæ¨¡å‹")
        print("  * Dataclassé£æ ¼")
        print("  * é€’å½’æ¨¡å‹")
        print("  * é«˜çº§éªŒè¯å’Œè½¬æ¢")
        print("  * é”™è¯¯å¤„ç†")
        
        print("\n- advanced: é«˜çº§Pydantic BaseModelæ„é€ æ–¹å¼æµ‹è¯•")
        print("  * æ€§èƒ½ä¼˜åŒ–æ„é€ ")
        print("  * å…ƒç¼–ç¨‹å’ŒåŠ¨æ€æ¨¡å‹åˆ›å»º")
        print("  * è£…é¥°å™¨æ¨¡å¼")
        print("  * ä¸­é—´ä»¶æ¨¡å¼")
        print("  * å¼‚æ­¥æ”¯æŒ")
        print("  * å¤æ‚éªŒè¯é€»è¾‘")
        print("  * æ•°æ®åº“é›†æˆ")
        print("  * é«˜çº§åºåˆ—åŒ–")
        print("  * ç‰ˆæœ¬æ§åˆ¶æ¨¡å‹")
        print("  * æ€§èƒ½å¯¹æ¯”")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Pydantic BaseModelæ„é€ æ–¹å¼æµ‹è¯•è¿è¡Œå™¨")
    parser.add_argument(
        '--tests', 
        nargs='*', 
        choices=['basic', 'advanced', 'all'],
        default=['all'],
        help="è¦è¿è¡Œçš„æµ‹è¯•ç±»å‹ (é»˜è®¤: all)"
    )
    parser.add_argument(
        '--list', 
        action='store_true',
        help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æµ‹è¯•"
    )
    parser.add_argument(
        '--quiet', 
        action='store_true',
        help="é™é»˜æ¨¡å¼ï¼Œåªæ˜¾ç¤ºæ‘˜è¦"
    )
    
    args = parser.parse_args()
    
    runner = PydanticTestRunner()
    
    if args.list:
        runner.list_available_tests()
        return 0
    
    if args.quiet:
        # é‡å®šå‘è¾“å‡ºåˆ°é™é»˜æ¨¡å¼
        import io
        old_stdout = sys.stdout
        sys.stdout = io.StringIO()
    
    try:
        if 'all' in args.tests:
            summary = runner.run_all_tests()
        else:
            summary = runner.run_specific_tests(args.tests)
        
        if args.quiet:
            # æ¢å¤è¾“å‡ºå¹¶åªæ˜¾ç¤ºæ‘˜è¦
            sys.stdout = old_stdout
            runner._print_summary(summary)
        
        # è¿”å›é€‚å½“çš„é€€å‡ºç 
        if summary['total_failures'] == 0 and summary['total_errors'] == 0:
            return 0
        else:
            return 1
            
    except KeyboardInterrupt:
        if args.quiet:
            sys.stdout = old_stdout
        print("\n\nâŒ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 130
    except Exception as e:
        if args.quiet:
            sys.stdout = old_stdout
        print(f"\n\nğŸ’¥ æµ‹è¯•è¿è¡Œå™¨å‘ç”Ÿé”™è¯¯: {e}")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code) 