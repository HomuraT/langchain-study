"""
å›è°ƒç»§æ‰¿å’Œä¼ æ’­æµ‹è¯•

æµ‹è¯•LangChainä¸­å›è°ƒçš„ç»§æ‰¿å’Œä¼ æ’­æœºåˆ¶ï¼ŒåŒ…æ‹¬ï¼š
- è¿è¡Œæ—¶å›è°ƒ vs æ„é€ å‡½æ•°å›è°ƒçš„åŒºåˆ«
- å›è°ƒåœ¨chainä¸­çš„ä¼ æ’­è¡Œä¸º
- åµŒå¥—ç»„ä»¶çš„å›è°ƒç»§æ‰¿
- å›è°ƒä½œç”¨åŸŸå’Œç”Ÿå‘½å‘¨æœŸ

é‡ç‚¹éªŒè¯ï¼š
1. è¿è¡Œæ—¶å›è°ƒä¼šä¼ é€’ç»™æ‰€æœ‰å­å¯¹è±¡
2. æ„é€ å‡½æ•°å›è°ƒåªä½œç”¨äºå®šä¹‰çš„å¯¹è±¡
3. å›è°ƒä¼ æ’­çš„å±‚çº§å…³ç³»
4. æ··åˆä½¿ç”¨æ—¶çš„ä¼˜å…ˆçº§
"""

import unittest
from typing import Any, Dict, List

from langchain_openai import ChatOpenAI
from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_core.output_parsers import StrOutputParser

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../../src'))

from src.config.api import apis


class TrackingCallbackHandler(BaseCallbackHandler):
    """è¿½è¸ªå›è°ƒå¤„ç†å™¨ï¼Œè®°å½•è§¦å‘æ¥æº"""
    
    def __init__(self, name: str):
        """
        åˆå§‹åŒ–è¿½è¸ªå›è°ƒå¤„ç†å™¨
        
        è¾“å…¥:
            name: str - å›è°ƒå¤„ç†å™¨åç§°
        è¾“å‡º: æ— 
        """
        self.name = name
        self.triggered_events = []
    
    def _record_event(self, event_name: str, source: str = "unknown") -> None:
        """
        è®°å½•äº‹ä»¶ä¿¡æ¯
        
        è¾“å…¥:
            event_name: str - äº‹ä»¶åç§°
            source: str - äº‹ä»¶æ¥æº
        è¾“å‡º: æ— 
        """
        self.triggered_events.append({
            'handler': self.name,
            'event': event_name,
            'source': source
        })
        print(f"ğŸ“ [{self.name}] {event_name} from {source}")
    
    def on_chat_model_start(self, serialized: Dict[str, Any], messages: List[List], **kwargs) -> None:
        """Chatæ¨¡å‹å¼€å§‹äº‹ä»¶"""
        model_name = serialized.get('id', ['', '', 'ChatOpenAI'])[-1]
        self._record_event("on_chat_model_start", f"ChatModel:{model_name}")
    
    def on_llm_end(self, response, **kwargs) -> None:
        """LLMç»“æŸäº‹ä»¶"""
        self._record_event("on_llm_end", "LLM")
    
    def on_chain_start(self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs) -> None:
        """Chainå¼€å§‹äº‹ä»¶"""
        chain_name = serialized.get('name', 'UnknownChain')
        self._record_event("on_chain_start", f"Chain:{chain_name}")
    
    def on_chain_end(self, outputs: Dict[str, Any], **kwargs) -> None:
        """Chainç»“æŸäº‹ä»¶"""
        self._record_event("on_chain_end", "Chain")
    
    def on_tool_start(self, serialized: Dict[str, Any], input_str: str, **kwargs) -> None:
        """Toolå¼€å§‹äº‹ä»¶"""
        tool_name = serialized.get('name', 'UnknownTool')
        self._record_event("on_tool_start", f"Tool:{tool_name}")
    
    def on_tool_end(self, output: str, **kwargs) -> None:
        """Toolç»“æŸäº‹ä»¶"""
        self._record_event("on_tool_end", "Tool")


class TestCallbackInheritance(unittest.TestCase):
    """å›è°ƒç»§æ‰¿æµ‹è¯•ç±»"""
    
    def setUp(self) -> None:
        """
        æµ‹è¯•å‰å‡†å¤‡
        
        è¾“å…¥: æ— 
        è¾“å‡º: æ— 
        """
        config = apis["local"]
        self.base_model = ChatOpenAI(
            model="gpt-4o-mini",
            base_url=config["base_url"],
            api_key=config["api_key"],
            temperature=0.7,
            max_tokens=100
        )
    
    def test_runtime_vs_constructor_callbacks(self) -> None:
        """
        æµ‹è¯•è¿è¡Œæ—¶å›è°ƒ vs æ„é€ å‡½æ•°å›è°ƒçš„åŒºåˆ«
        
        è¾“å…¥: æ— 
        è¾“å‡º: æ— 
        """
        print("\n=== æµ‹è¯•è¿è¡Œæ—¶å›è°ƒ vs æ„é€ å‡½æ•°å›è°ƒ ===")
        
        # 1. æ„é€ å‡½æ•°å›è°ƒ - åªä½œç”¨äºå®šä¹‰çš„å¯¹è±¡
        constructor_handler = TrackingCallbackHandler("Constructor")
        model_with_constructor = ChatOpenAI(
            model="gpt-4o-mini",
            base_url=apis["local"]["base_url"],
            api_key=apis["local"]["api_key"],
            callbacks=[constructor_handler],  # æ„é€ å‡½æ•°å›è°ƒ
            temperature=0.7,
            max_tokens=100
        )
        
        # 2. è¿è¡Œæ—¶å›è°ƒ - ä¼šä¼ é€’ç»™æ‰€æœ‰å­å¯¹è±¡
        runtime_handler = TrackingCallbackHandler("Runtime")
        
        messages = [HumanMessage(content="ç®€å•å›ç­”ï¼šä½ å¥½")]
        
        print("\n--- æµ‹è¯•1ï¼šåªä½¿ç”¨æ„é€ å‡½æ•°å›è°ƒ ---")
        try:
            response1 = model_with_constructor.invoke(messages)
            print(f"æ„é€ å‡½æ•°å›è°ƒå“åº”: {response1.content}")
            
            constructor_events = [e['event'] for e in constructor_handler.triggered_events]
            print(f"æ„é€ å‡½æ•°å›è°ƒäº‹ä»¶: {constructor_events}")
            
        except Exception as e:
            print(f"æ„é€ å‡½æ•°å›è°ƒæµ‹è¯•å¤±è´¥: {e}")
        
        print("\n--- æµ‹è¯•2ï¼šåªä½¿ç”¨è¿è¡Œæ—¶å›è°ƒ ---")
        try:
            response2 = self.base_model.invoke(messages, config={"callbacks": [runtime_handler]})
            print(f"è¿è¡Œæ—¶å›è°ƒå“åº”: {response2.content}")
            
            runtime_events = [e['event'] for e in runtime_handler.triggered_events]
            print(f"è¿è¡Œæ—¶å›è°ƒäº‹ä»¶: {runtime_events}")
            
        except Exception as e:
            print(f"è¿è¡Œæ—¶å›è°ƒæµ‹è¯•å¤±è´¥: {e}")
        
        # éªŒè¯ä¸¤ç§æ–¹å¼éƒ½èƒ½æ•è·åˆ°äº‹ä»¶
        self.assertGreater(len(constructor_handler.triggered_events), 0, "æ„é€ å‡½æ•°å›è°ƒåº”è¯¥æ•è·åˆ°äº‹ä»¶")
        self.assertGreater(len(runtime_handler.triggered_events), 0, "è¿è¡Œæ—¶å›è°ƒåº”è¯¥æ•è·åˆ°äº‹ä»¶")
        
        print("âœ… è¿è¡Œæ—¶å›è°ƒ vs æ„é€ å‡½æ•°å›è°ƒæµ‹è¯•é€šè¿‡")
    
    def test_callback_propagation_in_chains(self) -> None:
        """
        æµ‹è¯•å›è°ƒåœ¨chainä¸­çš„ä¼ æ’­
        
        è¾“å…¥: æ— 
        è¾“å‡º: æ— 
        """
        print("\n=== æµ‹è¯•å›è°ƒåœ¨Chainä¸­çš„ä¼ æ’­ ===")
        
        # åˆ›å»ºå¤æ‚çš„chain
        prompt = ChatPromptTemplate.from_template("è¯·å›ç­”ï¼š{question}")
        parser = StrOutputParser()
        
        # åªç»™æ¨¡å‹æ·»åŠ æ„é€ å‡½æ•°å›è°ƒ
        model_handler = TrackingCallbackHandler("ModelOnly")
        model_with_callback = ChatOpenAI(
            model="gpt-4o-mini",
            base_url=apis["local"]["base_url"],
            api_key=apis["local"]["api_key"],
            callbacks=[model_handler],
            temperature=0.7,
            max_tokens=100
        )
        
        # åˆ›å»ºchain
        chain = prompt | model_with_callback | parser
        
        # è¿è¡Œæ—¶å›è°ƒ
        runtime_handler = TrackingCallbackHandler("RuntimeChain")
        
        try:
            print("\n--- æµ‹è¯•1ï¼šä½¿ç”¨æ„é€ å‡½æ•°å›è°ƒï¼ˆä¸ä¼šä¼ æ’­åˆ°å…¶ä»–ç»„ä»¶ï¼‰ ---")
            response1 = chain.invoke({"question": "ä»€ä¹ˆæ˜¯AI?"})
            
            model_events = [e['event'] for e in model_handler.triggered_events]
            print(f"æ¨¡å‹å›è°ƒäº‹ä»¶: {model_events}")
            
            print("\n--- æµ‹è¯•2ï¼šä½¿ç”¨è¿è¡Œæ—¶å›è°ƒï¼ˆä¼šä¼ æ’­åˆ°æ‰€æœ‰ç»„ä»¶ï¼‰ ---")
            response2 = chain.invoke({"question": "ä»€ä¹ˆæ˜¯AI?"}, config={"callbacks": [runtime_handler]})
            
            runtime_events = [e['event'] for e in runtime_handler.triggered_events]
            print(f"è¿è¡Œæ—¶å›è°ƒäº‹ä»¶: {runtime_events}")
            
            # éªŒè¯ä¼ æ’­è¡Œä¸º
            # è¿è¡Œæ—¶å›è°ƒåº”è¯¥æ•è·æ›´å¤šäº‹ä»¶ï¼ˆåŒ…æ‹¬promptå’Œparserçš„äº‹ä»¶ï¼‰
            self.assertGreater(len(runtime_handler.triggered_events), 0, "è¿è¡Œæ—¶å›è°ƒåº”è¯¥æ•è·åˆ°chainäº‹ä»¶")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰chainç›¸å…³äº‹ä»¶
            chain_events = [e for e in runtime_handler.triggered_events if 'chain' in e['event']]
            self.assertGreater(len(chain_events), 0, "è¿è¡Œæ—¶å›è°ƒåº”è¯¥æ•è·åˆ°chainäº‹ä»¶")
            
            print("âœ… å›è°ƒä¼ æ’­æµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            print(f"âŒ å›è°ƒä¼ æ’­æµ‹è¯•å¤±è´¥: {e}")
            raise
    
    def test_nested_callback_inheritance(self) -> None:
        """
        æµ‹è¯•åµŒå¥—ç»„ä»¶çš„å›è°ƒç»§æ‰¿
        
        è¾“å…¥: æ— 
        è¾“å‡º: æ— 
        """
        print("\n=== æµ‹è¯•åµŒå¥—ç»„ä»¶å›è°ƒç»§æ‰¿ ===")
        
        # åˆ›å»ºåµŒå¥—çš„runnableç»“æ„
        def preprocessing_step(inputs):
            print(f"é¢„å¤„ç†æ­¥éª¤: {inputs}")
            return {"processed_question": f"å¤„ç†åçš„é—®é¢˜: {inputs['question']}"}
        
        def postprocessing_step(inputs):
            print(f"åå¤„ç†æ­¥éª¤: {inputs}")
            return f"æœ€ç»ˆç»“æœ: {inputs.content}"
        
        # æ„å»ºåµŒå¥—chain
        preprocessing = RunnableLambda(preprocessing_step)
        prompt = ChatPromptTemplate.from_template("{processed_question}")
        postprocessing = RunnableLambda(postprocessing_step)
        
        nested_chain = (
            preprocessing |
            prompt |
            self.base_model |
            postprocessing
        )
        
        # ä½¿ç”¨è¿è¡Œæ—¶å›è°ƒ
        nested_handler = TrackingCallbackHandler("NestedChain")
        
        try:
            result = nested_chain.invoke(
                {"question": "LangChainæ˜¯ä»€ä¹ˆï¼Ÿ"}, 
                config={"callbacks": [nested_handler]}
            )
            
            print(f"\nåµŒå¥—chainç»“æœ: {result}")
            
            # åˆ†ææ•è·çš„äº‹ä»¶
            events = nested_handler.triggered_events
            print(f"\n=== åµŒå¥—å›è°ƒäº‹ä»¶åˆ†æ ===")
            for event in events:
                print(f"[{event['handler']}] {event['event']} <- {event['source']}")
            
            # éªŒè¯åµŒå¥—ç»§æ‰¿
            event_types = [e['event'] for e in events]
            unique_events = set(event_types)
            
            print(f"\næ•è·çš„äº‹ä»¶ç±»å‹: {unique_events}")
            
            # åº”è¯¥æœ‰chainäº‹ä»¶ï¼ˆæ¥è‡ªåµŒå¥—ç»“æ„ï¼‰
            chain_events = [e for e in events if 'chain' in e['event']]
            self.assertGreater(len(chain_events), 0, "åº”è¯¥æ•è·åˆ°chainç›¸å…³äº‹ä»¶")
            
            print("âœ… åµŒå¥—å›è°ƒç»§æ‰¿æµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            print(f"âŒ åµŒå¥—å›è°ƒç»§æ‰¿æµ‹è¯•å¤±è´¥: {e}")
            raise
    
    def test_mixed_callback_scenarios(self) -> None:
        """
        æµ‹è¯•æ··åˆä½¿ç”¨å›è°ƒçš„åœºæ™¯
        
        è¾“å…¥: æ— 
        è¾“å‡º: æ— 
        """
        print("\n=== æµ‹è¯•æ··åˆå›è°ƒåœºæ™¯ ===")
        
        # åœºæ™¯ï¼šåŒæ—¶ä½¿ç”¨æ„é€ å‡½æ•°å›è°ƒå’Œè¿è¡Œæ—¶å›è°ƒ
        constructor_handler = TrackingCallbackHandler("Constructor")
        runtime_handler = TrackingCallbackHandler("Runtime")
        
        # åˆ›å»ºå¸¦æ„é€ å‡½æ•°å›è°ƒçš„æ¨¡å‹
        model_with_constructor = ChatOpenAI(
            model="gpt-4o-mini",
            base_url=apis["local"]["base_url"],
            api_key=apis["local"]["api_key"],
            callbacks=[constructor_handler],
            temperature=0.7,
            max_tokens=100
        )
        
        # åˆ›å»ºchain
        prompt = ChatPromptTemplate.from_template("å›ç­”: {text}")
        chain = prompt | model_with_constructor
        
        messages = {"text": "ä»€ä¹ˆæ˜¯Python?"}
        
        try:
            # åŒæ—¶ä½¿ç”¨ä¸¤ç§å›è°ƒ
            response = chain.invoke(messages, config={"callbacks": [runtime_handler]})
            
            print(f"\næ··åˆå›è°ƒå“åº”: {response.content}")
            
            # åˆ†æä¸¤ä¸ªå›è°ƒæ•è·çš„äº‹ä»¶
            constructor_events = constructor_handler.triggered_events
            runtime_events = runtime_handler.triggered_events
            
            print(f"\n--- æ„é€ å‡½æ•°å›è°ƒäº‹ä»¶ ---")
            for event in constructor_events:
                print(f"[{event['handler']}] {event['event']} <- {event['source']}")
            
            print(f"\n--- è¿è¡Œæ—¶å›è°ƒäº‹ä»¶ ---")
            for event in runtime_events:
                print(f"[{event['handler']}] {event['event']} <- {event['source']}")
            
            # éªŒè¯ä¸¤ç§å›è°ƒéƒ½ç”Ÿæ•ˆ
            self.assertGreater(len(constructor_events), 0, "æ„é€ å‡½æ•°å›è°ƒåº”è¯¥ç”Ÿæ•ˆ")
            self.assertGreater(len(runtime_events), 0, "è¿è¡Œæ—¶å›è°ƒåº”è¯¥ç”Ÿæ•ˆ")
            
            # è¿è¡Œæ—¶å›è°ƒåº”è¯¥æ•è·æ›´å¤šäº‹ä»¶ï¼ˆåŒ…æ‹¬chainäº‹ä»¶ï¼‰
            runtime_event_types = set(e['event'] for e in runtime_events)
            constructor_event_types = set(e['event'] for e in constructor_events)
            
            print(f"\næ„é€ å‡½æ•°å›è°ƒäº‹ä»¶ç±»å‹: {constructor_event_types}")
            print(f"è¿è¡Œæ—¶å›è°ƒäº‹ä»¶ç±»å‹: {runtime_event_types}")
            
            print("âœ… æ··åˆå›è°ƒåœºæ™¯æµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            print(f"âŒ æ··åˆå›è°ƒåœºæ™¯æµ‹è¯•å¤±è´¥: {e}")
            raise
    
    def test_callback_scope_isolation(self) -> None:
        """
        æµ‹è¯•å›è°ƒä½œç”¨åŸŸéš”ç¦»
        
        è¾“å…¥: æ— 
        è¾“å‡º: æ— 
        """
        print("\n=== æµ‹è¯•å›è°ƒä½œç”¨åŸŸéš”ç¦» ===")
        
        handler1 = TrackingCallbackHandler("Scope1")
        handler2 = TrackingCallbackHandler("Scope2")
        
        messages = [HumanMessage(content="æµ‹è¯•ä½œç”¨åŸŸ")]
        
        try:
            # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼Œä½¿ç”¨handler1
            print("\n--- ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆhandler1ï¼‰ ---")
            response1 = self.base_model.invoke(messages, config={"callbacks": [handler1]})
            print(f"å“åº”1: {response1.content}")
            
            # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼Œä½¿ç”¨handler2
            print("\n--- ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆhandler2ï¼‰ ---")
            response2 = self.base_model.invoke(messages, config={"callbacks": [handler2]})
            print(f"å“åº”2: {response2.content}")
            
            # ç¬¬ä¸‰æ¬¡è°ƒç”¨ï¼Œä¸ä½¿ç”¨å›è°ƒ
            print("\n--- ç¬¬ä¸‰æ¬¡è°ƒç”¨ï¼ˆæ— å›è°ƒï¼‰ ---")
            response3 = self.base_model.invoke(messages)
            print(f"å“åº”3: {response3.content}")
            
            # éªŒè¯ä½œç”¨åŸŸéš”ç¦»
            events1 = handler1.triggered_events
            events2 = handler2.triggered_events
            
            print(f"\nhandler1æ•è·äº‹ä»¶æ•°: {len(events1)}")
            print(f"handler2æ•è·äº‹ä»¶æ•°: {len(events2)}")
            
            # æ¯ä¸ªhandleråªåº”è¯¥æ•è·è‡ªå·±è°ƒç”¨çš„äº‹ä»¶
            self.assertGreater(len(events1), 0, "handler1åº”è¯¥æ•è·åˆ°äº‹ä»¶")
            self.assertGreater(len(events2), 0, "handler2åº”è¯¥æ•è·åˆ°äº‹ä»¶")
            
            # éªŒè¯äº‹ä»¶æ¥æºæ­£ç¡®
            for event in events1:
                self.assertEqual(event['handler'], "Scope1", "handler1çš„äº‹ä»¶æ ‡è®°åº”è¯¥æ­£ç¡®")
            
            for event in events2:
                self.assertEqual(event['handler'], "Scope2", "handler2çš„äº‹ä»¶æ ‡è®°åº”è¯¥æ­£ç¡®")
            
            print("âœ… å›è°ƒä½œç”¨åŸŸéš”ç¦»æµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            print(f"âŒ å›è°ƒä½œç”¨åŸŸéš”ç¦»æµ‹è¯•å¤±è´¥: {e}")
            raise


def main() -> int:
    """
    è¿è¡Œå›è°ƒç»§æ‰¿æµ‹è¯•çš„ä¸»å‡½æ•°
    
    Returns:
        int: é€€å‡ºç ï¼Œ0è¡¨ç¤ºæˆåŠŸ
    """
    print("ğŸ”— è¿è¡Œå›è°ƒç»§æ‰¿å’Œä¼ æ’­æµ‹è¯•")
    print("=" * 50)
    
    # è¿è¡Œæµ‹è¯•
    unittest.main(verbosity=2)
    return 0


if __name__ == "__main__":
    main() 