# LangChain Expression Language (LCEL) æµ‹è¯•å¥—ä»¶

ä¸€ä¸ªå…¨é¢çš„ LangChain Expression Language (LCEL) æµ‹è¯•æ¡†æ¶ï¼ŒéªŒè¯ LCEL çš„æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½å’Œé«˜çº§ç‰¹æ€§ï¼Œç¡®ä¿åœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„å¯é æ€§å’Œç¨³å®šæ€§ã€‚

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

LCELï¼ˆLangChain Expression Languageï¼‰æ˜¯ LangChain çš„æ ¸å¿ƒè¡¨è¾¾å¼è¯­è¨€ï¼Œæä¾›äº†ç®€æ´è€Œå¼ºå¤§çš„æ–¹å¼æ¥ç»„åˆå’Œæ‰§è¡Œå¤æ‚çš„ AI å·¥ä½œæµã€‚æœ¬æµ‹è¯•å¥—ä»¶æ¶µç›–ï¼š

- **8ä¸ªæ ¸å¿ƒæµ‹è¯•æ¨¡å—** - å…¨é¢è¦†ç›– LCEL åŠŸèƒ½å’Œå®é™…åº”ç”¨
- **450+ è¡Œè¯¦ç»†æ–‡æ¡£** - æ·±å…¥çš„ä½¿ç”¨æŒ‡å—å’Œæœ€ä½³å®è·µ  
- **è‡ªåŠ¨åŒ–æµ‹è¯•è¿è¡Œå™¨** - æ”¯æŒæ‰¹é‡æ‰§è¡Œå’Œè¯¦ç»†æŠ¥å‘Š
- **ç”Ÿäº§çº§é”™è¯¯å¤„ç†** - ç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ç½®è¦æ±‚

- Python 3.11+
- å·²æ¿€æ´»çš„è™šæ‹Ÿç¯å¢ƒ `.venv`
- æœ¬åœ° API æœåŠ¡ï¼ˆå¯é€‰ï¼Œç”¨äº AI æ¨¡å‹æµ‹è¯•ï¼‰

### å®‰è£…ä¾èµ–

```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate

# å®‰è£…æ ¸å¿ƒä¾èµ–
uv add langchain-openai langchain-core

# éªŒè¯å®‰è£…
python -c "import langchain_core; print('LangChain Core å®‰è£…æˆåŠŸ')"
```

### è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼ˆæ¨èï¼‰
python unitests/test_lcel/run_all_tests.py

# è¿è¡Œç‰¹å®šæµ‹è¯•æ¨¡å—
python unitests/test_lcel/run_all_tests.py --tests basic syntax applications

# é™é»˜æ¨¡å¼ï¼ˆä»…æ˜¾ç¤ºæ‘˜è¦ï¼‰
python unitests/test_lcel/run_all_tests.py --quiet

# æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æµ‹è¯•
python unitests/test_lcel/run_all_tests.py --list
```

### ä½¿ç”¨ unittest ç›´æ¥è¿è¡Œ

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m unittest discover unitests/test_lcel -v

# è¿è¡Œå•ä¸ªæµ‹è¯•æ–‡ä»¶
python -m unittest unitests.test_lcel.test_basic_composition -v

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–¹æ³•
python -m unittest unitests.test_lcel.test_basic_composition.TestLCELBasicComposition.test_runnable_sequence_basic -v
```

## ğŸ“‹ æµ‹è¯•æ¨¡å—è¯¦è§£

### 1. åŸºç¡€ç»„åˆåŠŸèƒ½ (`test_basic_composition.py`)

**æµ‹è¯•ç›®æ ‡**: RunnableSequence å’Œ RunnableParallel çš„æ ¸å¿ƒç»„åˆåŠŸèƒ½

**æ ¸å¿ƒç‰¹æ€§**:
- **RunnableSequence**: é¡ºåºæ‰§è¡Œé“¾ï¼Œå‰ä¸€æ­¥è¾“å‡ºä½œä¸ºä¸‹ä¸€æ­¥è¾“å…¥
- **RunnableParallel**: å¹¶è¡Œæ‰§è¡Œå¤šä¸ªä»»åŠ¡ï¼Œç›¸åŒè¾“å…¥åˆ†å‘ç»™æ‰€æœ‰ä»»åŠ¡
- **åµŒå¥—ç»„åˆ**: å¤æ‚çš„åºåˆ—å’Œå¹¶è¡Œç»“æ„ç»„åˆ
- **é”™è¯¯ä¼ æ’­**: é“¾ä¸­é”™è¯¯çš„æ­£ç¡®ä¼ æ’­æœºåˆ¶

**å®é™…åº”ç”¨åœºæ™¯**:
```python
# ğŸ“Š æ•°æ®å¤„ç†ç®¡é“
data_pipeline = preprocess | vectorize | similarity_search | rank_results

# ğŸ¤– AI å·¥ä½œæµ
ai_workflow = user_input | build_prompt | call_model | parse_response

# ğŸ”„ å¹¶è¡Œåˆ†æ
parallel_analysis = RunnableParallel({
    "sentiment": sentiment_analyzer,
    "keywords": keyword_extractor, 
    "summary": text_summarizer,
    "metadata": extract_metadata
})
```

**å…³é”®æµ‹è¯•ç”¨ä¾‹**:
- âœ… åŸºç¡€åºåˆ—ç»„åˆå’Œè¾“å‡ºéªŒè¯
- âœ… å¹¶è¡Œæ‰§è¡Œå’Œç»“æœèšåˆ
- âœ… åµŒå¥—ç»“æ„çš„å¤æ‚ç»„åˆ
- âœ… é”™è¯¯åœ¨é“¾ä¸­çš„æ­£ç¡®ä¼ æ’­
- âœ… å•å…ƒç´ å’Œç©ºç»“æ„çš„è¾¹ç•Œæƒ…å†µ

### 2. è¯­æ³•æ“ä½œç¬¦åŠŸèƒ½ (`test_syntax_operators.py`)

**æµ‹è¯•ç›®æ ‡**: `|` æ“ä½œç¬¦å’Œ `.pipe()` æ–¹æ³•çš„è¯­æ³•ç³–åŠŸèƒ½

**æ ¸å¿ƒç‰¹æ€§**:
- **ç®¡é“æ“ä½œç¬¦ `|`**: ç±»ä¼¼ Unix ç®¡é“çš„ç›´è§‚è¯­æ³•
- **`.pipe()` æ–¹æ³•**: é¢å‘å¯¹è±¡é£æ ¼çš„é“¾å¼è°ƒç”¨
- **è¯­æ³•ç­‰ä»·æ€§**: ç¡®ä¿ä¸åŒè¯­æ³•äº§ç”Ÿç›¸åŒç»“æœ
- **å¯è¯»æ€§ä¼˜åŒ–**: æä¾›å¤šç§è¡¨è¾¾æ–¹å¼

**è¯­æ³•å¯¹æ¯”ç¤ºä¾‹**:
```python
# ç®¡é“æ“ä½œç¬¦é£æ ¼ï¼ˆæ¨èï¼‰
chain = prompt | model | parser

# .pipe() æ–¹æ³•é£æ ¼
chain = (prompt
         .pipe(model)
         .pipe(parser))

# ä¸ AI æ¨¡å‹ç»“åˆ
ai_chain = (
    ChatPromptTemplate.from_template("å›ç­”: {question}") |
    ChatOpenAI(model="gpt-4o-mini") |
    StrOutputParser()
)
```

**å…³é”®æµ‹è¯•ç”¨ä¾‹**:
- âœ… `|` æ“ä½œç¬¦åŸºæœ¬åŠŸèƒ½å’Œå¤æ‚é“¾å¼
- âœ… `.pipe()` æ–¹æ³•çš„æµç•…æ¥å£
- âœ… ä¸¤ç§è¯­æ³•çš„å®Œå…¨ç­‰ä»·æ€§éªŒè¯
- âœ… æ··åˆè¯­æ³•é£æ ¼çš„å…¼å®¹æ€§
- âœ… ä¸ Prompt å’Œæ¨¡å‹çš„æ— ç¼é›†æˆ

### 3. ç±»å‹è½¬æ¢åŠŸèƒ½ (`test_type_coercion.py`)

**æµ‹è¯•ç›®æ ‡**: LCEL çš„æ™ºèƒ½ç±»å‹è‡ªåŠ¨è½¬æ¢æœºåˆ¶

**æ ¸å¿ƒç‰¹æ€§**:
- **å­—å…¸ â†’ RunnableParallel**: è‡ªåŠ¨å°†å­—å…¸è½¬æ¢ä¸ºå¹¶è¡Œæ‰§è¡Œ
- **å‡½æ•° â†’ RunnableLambda**: è‡ªåŠ¨åŒ…è£…æ™®é€šå‡½æ•°ä¸ºå¯è¿è¡Œå¯¹è±¡
- **åµŒå¥—è½¬æ¢**: å¤æ‚åµŒå¥—ç»“æ„çš„é€’å½’è½¬æ¢
- **ç±»å‹ä¿æŒ**: è½¬æ¢è¿‡ç¨‹ä¸­ä¿æŒæ•°æ®ç±»å‹å®Œæ•´æ€§

**è½¬æ¢ç¤ºä¾‹**:
```python
# å­—å…¸è‡ªåŠ¨è½¬æ¢ä¸º RunnableParallel
processing_pipeline = {
    "analysis": analyze_sentiment,      # å‡½æ•°è‡ªåŠ¨è½¬æ¢
    "extraction": extract_keywords,     # å‡½æ•°è‡ªåŠ¨è½¬æ¢  
    "original": RunnablePassthrough(), # ä¿æŒåŸå§‹è¾“å…¥
    "metadata": {                       # åµŒå¥—å­—å…¸è½¬æ¢
        "length": lambda x: len(x),
        "word_count": lambda x: len(x.split())
    }
} | combine_results

# ç›´æ¥åœ¨ç®¡é“ä¸­ä½¿ç”¨
result = processing_pipeline.invoke("è¾“å…¥æ–‡æœ¬")
```

**å…³é”®æµ‹è¯•ç”¨ä¾‹**:
- âœ… å­—å…¸åˆ° RunnableParallel çš„åŸºç¡€è½¬æ¢
- âœ… å‡½æ•°åˆ° RunnableLambda çš„è‡ªåŠ¨åŒ…è£…
- âœ… åµŒå¥—å­—å…¸ç»“æ„çš„é€’å½’è½¬æ¢
- âœ… æ··åˆç±»å‹ï¼ˆå‡½æ•°ã€Runnableã€å­—å…¸ï¼‰çš„ç»„åˆ
- âœ… è‡ªå®šä¹‰ç±»å’Œæ–¹æ³•çš„è½¬æ¢æ”¯æŒ

### 4. å¼‚æ­¥æ“ä½œåŠŸèƒ½ (`test_async_operations.py`)

**æµ‹è¯•ç›®æ ‡**: LCEL çš„å¼‚æ­¥æ‰§è¡Œèƒ½åŠ›å’Œæ€§èƒ½ä¼˜åŒ–

**æ ¸å¿ƒç‰¹æ€§**:
- **å¼‚æ­¥è°ƒç”¨**: `ainvoke()`, `astream()`, `abatch()` æ–¹æ³•
- **å¹¶å‘æ‰§è¡Œ**: å¤šä»»åŠ¡åŒæ—¶å¤„ç†æå‡ååé‡
- **æ€§èƒ½ä¼˜åŒ–**: I/O å¯†é›†å‹ä»»åŠ¡çš„å¼‚æ­¥ä¼˜åŒ–
- **é”™è¯¯å¤„ç†**: å¼‚æ­¥ç¯å¢ƒä¸‹çš„å¼‚å¸¸ç®¡ç†

**å¼‚æ­¥ä½¿ç”¨ç¤ºä¾‹**:
```python
# å¼‚æ­¥å¤„ç†é“¾
async_chain = async_preprocess | model | async_postprocess

# å¼‚æ­¥è°ƒç”¨
result = await async_chain.ainvoke("è¾“å…¥æ–‡æœ¬")

# å¼‚æ­¥æ‰¹å¤„ç†ï¼ˆé«˜æ€§èƒ½ï¼‰
inputs = ["æ–‡æœ¬1", "æ–‡æœ¬2", "æ–‡æœ¬3"] 
results = await async_chain.abatch(inputs)

# å¹¶å‘æ‰§è¡Œå¤šä¸ªç‹¬ç«‹ä»»åŠ¡
tasks = [async_chain.ainvoke(text) for text in inputs]
results = await asyncio.gather(*tasks)
```

**å…³é”®æµ‹è¯•ç”¨ä¾‹**:
- âœ… åŸºæœ¬å¼‚æ­¥è°ƒç”¨åŠŸèƒ½éªŒè¯
- âœ… å¼‚æ­¥ä¸åŒæ­¥æ€§èƒ½å¯¹æ¯”åˆ†æ
- âœ… å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œæ€§èƒ½æµ‹è¯•
- âœ… å¼‚æ­¥ç¯å¢ƒä¸‹çš„é”™è¯¯å¤„ç†
- âœ… æ··åˆåŒæ­¥å¼‚æ­¥å‡½æ•°çš„é“¾å¼è°ƒç”¨

### 5. æµå¼ä¼ è¾“åŠŸèƒ½ (`test_streaming.py`)

**æµ‹è¯•ç›®æ ‡**: å®æ—¶å“åº”å’Œé€æ­¥å†…å®¹ç”Ÿæˆèƒ½åŠ›

**æ ¸å¿ƒç‰¹æ€§**:
- **åŒæ­¥æµå¼**: `stream()` æ–¹æ³•å®ç°é€æ­¥è¾“å‡º
- **å¼‚æ­¥æµå¼**: `astream()` æ–¹æ³•æ”¯æŒå¼‚æ­¥æµå¼å¤„ç†
- **å®æ—¶å“åº”**: å‡å°‘ç”¨æˆ·ç­‰å¾…æ—¶é—´ï¼Œæ”¹å–„äº¤äº’ä½“éªŒ
- **æµå¼é¢„å¤„ç†**: ç»“åˆé¢„å¤„ç†æ­¥éª¤çš„æµå¼è¾“å‡º

**æµå¼åº”ç”¨ç¤ºä¾‹**:
```python
# æµå¼èŠå¤©æœºå™¨äºº
streaming_chat = prompt | model | StrOutputParser()

# å®æ—¶æ˜¾ç¤ºå“åº”
print("AI: ", end="")
for chunk in streaming_chat.stream({"question": "ä»€ä¹ˆæ˜¯ LCEL?"}):
    print(chunk, end="", flush=True)

# å¼‚æ­¥æµå¼å¤„ç†
async for chunk in streaming_chat.astream(input_data):
    await process_chunk_realtime(chunk)
```

**åº”ç”¨åœºæ™¯**:
- ğŸ’¬ **èŠå¤©ç•Œé¢**: æ¨¡æ‹Ÿæ‰“å­—æ•ˆæœçš„å®æ—¶å¯¹è¯
- âœï¸ **å†…å®¹ç”Ÿæˆ**: å®æ—¶æ˜¾ç¤ºæ–‡ç« ã€ä»£ç ç”Ÿæˆè¿‡ç¨‹
- ğŸ“Š **æ•°æ®åˆ†æ**: è¾¹å¤„ç†è¾¹å±•ç¤ºåˆ†æç»“æœ
- ğŸ¯ **ç”¨æˆ·ä½“éªŒ**: æä¾›å³æ—¶åé¦ˆï¼Œå‡å°‘æ„ŸçŸ¥å»¶è¿Ÿ

**å…³é”®æµ‹è¯•ç”¨ä¾‹**:
- âœ… åŸºç¡€æµå¼è¾“å‡ºåŠŸèƒ½å’Œå†…å®¹éªŒè¯
- âœ… å¼‚æ­¥æµå¼ä¼ è¾“æ€§èƒ½æµ‹è¯•
- âœ… å¸¦é¢„å¤„ç†çš„æµå¼è¾“å‡ºç®¡é“
- âœ… æµå¼è¿‡ç¨‹ä¸­çš„é”™è¯¯å¤„ç†

### 6. å¹¶è¡Œæ‰§è¡ŒåŠŸèƒ½ (`test_parallel_execution.py`)

**æµ‹è¯•ç›®æ ‡**: æ‰¹å¤„ç†å’Œå¹¶è¡Œä¼˜åŒ–çš„æ€§èƒ½æå‡

**æ ¸å¿ƒç‰¹æ€§**:
- **æ‰¹å¤„ç†**: `batch()` æ–¹æ³•å®ç°é«˜æ•ˆæ‰¹é‡å¤„ç†
- **å¼‚æ­¥æ‰¹å¤„ç†**: `abatch()` æ–¹æ³•æä¾›å¼‚æ­¥æ‰¹é‡å¤„ç†
- **æ€§èƒ½ä¼˜åŒ–**: å¹¶è¡Œæ‰§è¡Œæ˜¾è‘—æå‡å¤„ç†é€Ÿåº¦
- **èµ„æºç®¡ç†**: é«˜æ•ˆåˆ©ç”¨è®¡ç®—èµ„æº

**æ€§èƒ½ä¼˜åŒ–ç¤ºä¾‹**:
```python
# æ‰¹é‡æ–‡æ¡£å¤„ç†
documents = [f"æ–‡æ¡£{i}" for i in range(100)]

# ä¸²è¡Œå¤„ç†ï¼ˆæ…¢ï¼‰
results = [chain.invoke(doc) for doc in documents]

# æ‰¹å¤„ç†ï¼ˆå¿«ï¼‰
results = chain.batch(documents)  # 3-5x æ€§èƒ½æå‡

# å¼‚æ­¥æ‰¹å¤„ç†ï¼ˆæœ€å¿«ï¼‰
results = await chain.abatch(documents)
```

**æ€§èƒ½åŸºå‡†**:
| å¤„ç†æ–¹å¼ | 100ä¸ªæ–‡æ¡£ | æ€§èƒ½æå‡ | é€‚ç”¨åœºæ™¯ |
|---------|----------|----------|----------|
| ä¸²è¡Œå¤„ç† | 10.0s | 1x | å°æ‰¹é‡ |
| æ‰¹å¤„ç† | 3.2s | 3.1x | ä¸­æ‰¹é‡ |
| å¼‚æ­¥æ‰¹å¤„ç† | 2.1s | 4.8x | å¤§æ‰¹é‡ |

**å…³é”®æµ‹è¯•ç”¨ä¾‹**:
- âœ… åŸºç¡€æ‰¹å¤„ç†åŠŸèƒ½å’Œç»“æœéªŒè¯
- âœ… å¹¶è¡Œä¸ä¸²è¡Œæ‰§è¡Œæ€§èƒ½å¯¹æ¯”
- âœ… å¼‚æ­¥æ‰¹å¤„ç†æ€§èƒ½åŸºå‡†æµ‹è¯•
- âœ… å¤§æ‰¹é‡æ•°æ®å¤„ç†å‹åŠ›æµ‹è¯•

### 7. é”™è¯¯å¤„ç†åŠŸèƒ½ (`test_error_handling.py`)

**æµ‹è¯•ç›®æ ‡**: ç”Ÿäº§ç¯å¢ƒä¸­çš„é”™è¯¯å¤„ç†å’Œç³»ç»Ÿç¨³å®šæ€§

**æ ¸å¿ƒç‰¹æ€§**:
- **é”™è¯¯ä¼ æ’­**: é“¾ä¸­é”™è¯¯çš„æ­£ç¡®ä¼ æ’­æœºåˆ¶
- **å¹¶è¡Œé”™è¯¯**: å¹¶è¡Œæ‰§è¡Œä¸­éƒ¨åˆ†å¤±è´¥çš„å¤„ç†ç­–ç•¥
- **å¼‚æ­¥é”™è¯¯**: å¼‚æ­¥ç¯å¢ƒä¸‹çš„å¼‚å¸¸ç®¡ç†
- **é”™è¯¯æ¢å¤**: è‡ªåŠ¨é‡è¯•å’Œä¼˜é›…é™çº§

**é”™è¯¯å¤„ç†ç­–ç•¥**:
```python
# é”™è¯¯æ¢å¤æœºåˆ¶
def error_recovery_chain(input_text):
    try:
        return primary_chain.invoke(input_text)
    except APIError as e:
        logger.warning(f"ä¸»é“¾å¤±è´¥ï¼Œå¯ç”¨å¤‡ç”¨é“¾: {e}")
        return fallback_chain.invoke(input_text)
    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {e}")
        return f"å¤„ç†å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•: {input_text}"

# æ¡ä»¶é”™è¯¯å¤„ç†
safe_chain = (
    validate_input |           # è¾“å…¥éªŒè¯
    safe_preprocess |          # å®‰å…¨é¢„å¤„ç†
    conditional_processor |    # æ¡ä»¶å¤„ç†
    safe_postprocess           # å®‰å…¨åå¤„ç†
)
```

**ç”Ÿäº§çº§é”™è¯¯å¤„ç†**:
- ğŸ›¡ï¸ **å®¹é”™æœºåˆ¶**: éƒ¨åˆ†ç»„ä»¶å¤±è´¥æ—¶ç³»ç»Ÿç»§ç»­è¿è¡Œ
- ğŸ”„ **è‡ªåŠ¨é‡è¯•**: ç½‘ç»œå¼‚å¸¸ã€APIé™æµçš„æ™ºèƒ½é‡è¯•
- ğŸ“Š **é”™è¯¯ç›‘æ§**: å®æ—¶é”™è¯¯ç»Ÿè®¡å’Œå¥åº·çŠ¶æ€ç›‘æ§
- ğŸ¯ **ä¼˜é›…é™çº§**: ä¸»åŠŸèƒ½å¤±è´¥æ—¶çš„å¤‡ç”¨æ–¹æ¡ˆ

**å…³é”®æµ‹è¯•ç”¨ä¾‹**:
- âœ… åºåˆ—é“¾ä¸­é”™è¯¯çš„æ­£ç¡®ä¼ æ’­
- âœ… å¹¶è¡Œæ‰§è¡Œä¸­çš„é”™è¯¯éš”ç¦»å¤„ç†
- âœ… å¼‚æ­¥æ“ä½œçš„é”™è¯¯æ•è·å’Œå¤„ç†
- âœ… æ‰¹å¤„ç†ä¸­çš„é”™è¯¯æ¢å¤æœºåˆ¶

### 8. ChatOpenAIåº”ç”¨åœºæ™¯ (`test_chatopenai_applications.py`)

**æµ‹è¯•ç›®æ ‡**: ChatOpenAIä¸LCELç»“åˆçš„å®é™…åº”ç”¨åœºæ™¯å’Œç»å…¸æ¡ˆä¾‹

**æ ¸å¿ƒç‰¹æ€§**:
- **æ™ºèƒ½é—®ç­”åŠ©æ‰‹**: è‡ªåŠ¨é—®é¢˜åˆ†ç±»å’Œä¸ªæ€§åŒ–å›ç­”
- **æ–‡æœ¬åˆ†æä¸æ€»ç»“**: å¹¶è¡Œåˆ†æã€å…³é”®è¯æå–ã€æ™ºèƒ½æ€»ç»“
- **è§’è‰²æ‰®æ¼”å¯¹è¯**: å¤šè§’è‰²åŠ¨æ€åˆ‡æ¢å’Œä¸ªæ€§åŒ–å“åº”
- **å¤šæ­¥éª¤æ¨ç†é“¾**: å¤æ‚é—®é¢˜åˆ†è§£ã€é€æ­¥åˆ†æã€ç»¼åˆç»“è®º
- **æ¡ä»¶å¯¹è¯æµ**: æƒ…æ„Ÿæ£€æµ‹å’ŒåŠ¨æ€å“åº”ç­–ç•¥
- **å†…å®¹ç”Ÿæˆç®¡é“**: ä¸»é¢˜æ‰©å±•ã€å†…å®¹ç”Ÿæˆã€ä¼˜åŒ–å¤„ç†
- **å¼‚æ­¥æ‰¹å¤„ç†**: é«˜æ•ˆçš„æ‰¹é‡ä»»åŠ¡å¤„ç†
- **Tokenå¼€é”€è¿½è¸ª**: è¯¦ç»†çš„æˆæœ¬åˆ†æå’Œæ€§èƒ½ç›‘æ§

**Tokenå¼€é”€ç»Ÿè®¡åŠŸèƒ½** ğŸ¯:
æœ¬æ¨¡å—æä¾›äº†ä¸‰ç§ä¸åŒçº§åˆ«çš„tokenä½¿ç”¨è¿½è¸ªæ–¹æ³•ï¼Œå¸®åŠ©ä½ ç›‘æ§å’Œä¼˜åŒ–AIåº”ç”¨çš„æˆæœ¬ï¼š

#### æ–¹æ³•1: å†…åµŒå¼Tokenè¿½è¸ª (`test_content_generation_pipeline_with_details`)
**ç‰¹ç‚¹**: å¤æ‚ä½†å…¨é¢ï¼Œtokenä¿¡æ¯ä½œä¸ºç®¡é“ç»“æœçš„ä¸€éƒ¨åˆ†

```python
# æ¯ä¸ªæ­¥éª¤éƒ½æœ‰ç‹¬ç«‹çš„callbackè¿½è¸ª
detailed_pipeline = (
    RunnablePassthrough.assign(
        step1_outline=RunnableLambda(track_step_tokens("outline", step1_callback))
    )
    | RunnablePassthrough.assign(
        step2_content=RunnableLambda(track_step_tokens("content", step2_callback))
    )
    | RunnablePassthrough.assign(
        token_usage=RunnableLambda(lambda x: {
            "step1_outline": dict(step1_callback.usage_metadata),
            "step2_content": dict(step2_callback.usage_metadata),
            # ... æ›´å¤šæ­¥éª¤
        })
    )
)

# æ‰§è¡Œåå¯ä»¥ä»ç»“æœä¸­è·å–tokenä¿¡æ¯
result = detailed_pipeline.invoke({"topic": "AIåº”ç”¨"})
token_stats = result["metadata"]["token_usage"]
```

**è¾“å‡ºç¤ºä¾‹**:
```
ğŸ” æ­¥éª¤ [outline] Tokenä½¿ç”¨æƒ…å†µ:
  æ¨¡å‹: gpt-4o-mini-2024-07-18
  è¾“å…¥tokens: 25
  è¾“å‡ºtokens: 156
  æ€»tokens: 181

ğŸ“Š æ€»ä½“Tokenä½¿ç”¨ç»Ÿè®¡:
  step1_outline:
    æ¨¡å‹: gpt-4o-mini-2024-07-18
    è¾“å…¥: 25 tokens
    è¾“å‡º: 156 tokens
    å°è®¡: 181 tokens

ğŸ¯ å…¨æµç¨‹æ±‡æ€»:
  æ€»è¾“å…¥tokens: 542
  æ€»è¾“å‡ºtokens: 1,247
  æ€»è®¡tokens: 1,789
```

#### æ–¹æ³•2: Context Managerè¿½è¸ª (`test_content_generation_with_token_tracking_v2`) â­ æ¨è
**ç‰¹ç‚¹**: ç®€æ´é«˜æ•ˆï¼Œè‡ªåŠ¨èšåˆæ•´ä¸ªç®¡é“çš„tokenä½¿ç”¨

```python
from langchain_core.callbacks import get_usage_metadata_callback

# ä½¿ç”¨context managerè‡ªåŠ¨è¿½è¸ª
with get_usage_metadata_callback() as cb:
    # æ„å»ºå’Œæ‰§è¡Œç®¡é“
    pipeline = (
        RunnablePassthrough.assign(outline=topic_expander | model | parser)
        | RunnablePassthrough.assign(content=content_generator | model | parser)
        | RunnablePassthrough.assign(optimized=content_optimizer | model | parser)
    )
    
    result = pipeline.invoke({"topic": "AIåœ¨æ•™è‚²ä¸­çš„åº”ç”¨"})
    
    # è·å–èšåˆçš„tokenä½¿ç”¨æƒ…å†µ
    total_usage = cb.usage_metadata

# åˆ†ætokenä½¿ç”¨
for model_name, usage_data in total_usage.items():
    print(f"æ¨¡å‹: {model_name}")
    print(f"  è¾“å…¥tokens: {usage_data['input_tokens']}")
    print(f"  è¾“å‡ºtokens: {usage_data['output_tokens']}")
    print(f"  æ€»è®¡: {usage_data['total_tokens']}")
```

**è¾“å‡ºç¤ºä¾‹**:
```
ğŸ“Š Tokenä½¿ç”¨ç»Ÿè®¡:

æ¨¡å‹: gpt-4o-mini-2024-07-18
  è¾“å…¥tokens: 542
  è¾“å‡ºtokens: 1247
  æ€»tokens: 1789
  è¾“å…¥è¯¦æƒ…: {'audio': 0, 'cache_read': 0}
  è¾“å‡ºè¯¦æƒ…: {'audio': 0, 'reasoning': 0}

ğŸ¯ æ•´ä¸ªç®¡é“æ±‡æ€»:
  æ€»è¾“å…¥tokens: 542
  æ€»è¾“å‡ºtokens: 1247
  æ€»è®¡tokens: 1789
```

#### æ–¹æ³•3: åˆ†æ­¥å®æ—¶è¿½è¸ª (`test_content_generation_step_by_step_tokens`)
**ç‰¹ç‚¹**: æœ€è¯¦ç»†çš„åˆ†æï¼Œå®æ—¶æ˜¾ç¤ºæ¯ä¸ªæ­¥éª¤çš„tokenæ¶ˆè€—

```python
# åˆ†åˆ«æ‰§è¡Œæ¯ä¸ªæ­¥éª¤å¹¶å®æ—¶è¿½è¸ª
step_results = {}
step_tokens = {}

# æ­¥éª¤1: ç”Ÿæˆå¤§çº²
print("\nğŸš€ æ­¥éª¤1: ç”Ÿæˆä¸»é¢˜å¤§çº²...")
with get_usage_metadata_callback() as cb1:
    outline = outline_chain.invoke({"topic": test_topic})
    step_tokens["step1"] = dict(cb1.usage_metadata)
    print(f"âœ… å¤§çº²ç”Ÿæˆå®Œæˆ ({len(outline.split())} è¯)")

# æ­¥éª¤2: ç”Ÿæˆå†…å®¹  
print("\nğŸš€ æ­¥éª¤2: åŸºäºå¤§çº²ç”Ÿæˆæ–‡ç« å†…å®¹...")
with get_usage_metadata_callback() as cb2:
    content = content_chain.invoke({"outline": outline})
    step_tokens["step2"] = dict(cb2.usage_metadata)
    print(f"âœ… æ–‡ç« å†…å®¹ç”Ÿæˆå®Œæˆ ({len(content.split())} è¯)")

# è®¡ç®—æ•ˆç‡æŒ‡æ ‡
efficiency_ratio = total_output_tokens / total_input_tokens
print(f"è¾“å‡º/è¾“å…¥æ¯”ç‡: {efficiency_ratio:.2f}")
```

**è¾“å‡ºç¤ºä¾‹**:
```
ğŸš€ æ­¥éª¤1: ç”Ÿæˆä¸»é¢˜å¤§çº²...
âœ… å¤§çº²ç”Ÿæˆå®Œæˆ (156 è¯)
   Tokenä½¿ç”¨ - è¾“å…¥: 25, è¾“å‡º: 156, æ€»è®¡: 181

ğŸš€ æ­¥éª¤2: åŸºäºå¤§çº²ç”Ÿæˆæ–‡ç« å†…å®¹...
âœ… æ–‡ç« å†…å®¹ç”Ÿæˆå®Œæˆ (487 è¯)  
   Tokenä½¿ç”¨ - è¾“å…¥: 198, è¾“å‡º: 487, æ€»è®¡: 685

ğŸ“Š å®Œæ•´Tokenä½¿ç”¨åˆ†æ:
==================================================

ğŸ“ ä¸»é¢˜æ‰©å±•ä¸ºå¤§çº²:
   æ¨¡å‹: gpt-4o-mini-2024-07-18
   è¾“å…¥tokens: 25
   è¾“å‡ºtokens: 156
   æ­¥éª¤æ€»è®¡: 181

ğŸ“ å¤§çº²ç”Ÿæˆæ–‡ç« :
   æ¨¡å‹: gpt-4o-mini-2024-07-18
   è¾“å…¥tokens: 198
   è¾“å‡ºtokens: 487
   æ­¥éª¤æ€»è®¡: 685

ğŸ¯ å…¨æµç¨‹æ±‡æ€»:
   æ€»è¾“å…¥tokens: 542
   æ€»è¾“å‡ºtokens: 1247
   æµç¨‹æ€»è®¡tokens: 1789
   è¾“å‡º/è¾“å…¥æ¯”ç‡: 2.30

ğŸ“„ å†…å®¹ç»Ÿè®¡:
   åŸå§‹ä¸»é¢˜: äººå·¥æ™ºèƒ½åœ¨æ•™è‚²ä¸­çš„åº”ç”¨
   å¤§çº²å­—æ•°: 156 è¯
   æ–‡ç« å­—æ•°: 487 è¯
   ä¼˜åŒ–åå­—æ•°: 604 è¯
```

#### Tokenå¼€é”€ä¼˜åŒ–å»ºè®® ğŸ’¡:

**æˆæœ¬æ§åˆ¶ç­–ç•¥**:
- ğŸ¯ **ä½¿ç”¨æ–¹æ³•2è¿›è¡Œæ—¥å¸¸ç›‘æ§** - ç®€æ´ä¸”è¶³å¤Ÿè¯¦ç»†
- ğŸ” **ä½¿ç”¨æ–¹æ³•3è¿›è¡Œæ·±åº¦åˆ†æ** - è¯†åˆ«é«˜æ¶ˆè€—æ­¥éª¤
- âš–ï¸ **å¹³è¡¡æ¨¡å‹é€‰æ‹©** - æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©åˆé€‚çš„æ¨¡å‹
- ğŸ“Š **æ‰¹å¤„ç†ä¼˜åŒ–** - æ‰¹é‡å¤„ç†é™ä½å¹³å‡æˆæœ¬

**æ€§èƒ½ç›‘æ§æŒ‡æ ‡**:
- **Tokenæ•ˆç‡æ¯”**: è¾“å‡ºtokens/è¾“å…¥tokensï¼ˆç›®æ ‡: >1.5ï¼‰
- **æ­¥éª¤è€—æ—¶**: è¯†åˆ«ç“¶é¢ˆæ­¥éª¤è¿›è¡Œä¼˜åŒ–
- **æ‰¹å¤„ç†æ•ˆç‡**: å•ä¸ªvsæ‰¹é‡å¤„ç†çš„æˆæœ¬å¯¹æ¯”
- **é”™è¯¯é‡è¯•æˆæœ¬**: å¤±è´¥é‡è¯•å¯¼è‡´çš„é¢å¤–å¼€é”€

**å®é™…åº”ç”¨åœºæ™¯**:
```python
# ğŸ¤– æ™ºèƒ½é—®ç­”åŠ©æ‰‹
qa_chain = (
    question_classifier
    | RunnableParallel({
        "type": lambda x: x["type"],
        "answer": qa_prompt | model | str_parser
    })
    | answer_formatter
)

# ğŸ“Š æ–‡æœ¬åˆ†æç®¡é“
analysis_chain = (
    text_preprocessor
    | RunnableParallel({
        "analysis": analysis_prompt | model | str_parser,
        "summary": summary_prompt | model | str_parser,
        "keywords": keywords_prompt | model | str_parser
    })
    | result_formatter
)

# ğŸ­ è§’è‰²æ‰®æ¼”å¯¹è¯
role_dialogue = (
    role_selector
    | RunnableLambda(create_role_prompt)
    | creative_model
    | str_parser
)

# ğŸ§  å¤šæ­¥æ¨ç†é“¾
reasoning_chain = (
    RunnablePassthrough.assign(sub_questions=decompose_prompt | model)
    | RunnablePassthrough.assign(analysis=analyze_prompt | model)
    | RunnablePassthrough.assign(final_answer=synthesize_prompt | model)
)
```

**åº”ç”¨åœºæ™¯**:
- ğŸ’¬ **å®¢æœæœºå™¨äºº**: æ™ºèƒ½åˆ†ç±»ç”¨æˆ·é—®é¢˜ï¼Œæä¾›ä¸ªæ€§åŒ–è§£ç­”
- ğŸ“š **æ•™è‚²å¹³å°**: è§’è‰²æ‰®æ¼”æ•™å­¦ï¼Œå¤šæ­¥éª¤é—®é¢˜è§£æ  
- ğŸ“ **å†…å®¹åˆ›ä½œ**: è‡ªåŠ¨ç”Ÿæˆæ–‡ç« ã€åˆ†æä¼˜åŒ–å†…å®¹
- ğŸ” **æ–‡æ¡£åˆ†æ**: æ‰¹é‡å¤„ç†æ–‡æ¡£ï¼Œæå–å…³é”®ä¿¡æ¯
- ğŸ¯ **å†³ç­–æ”¯æŒ**: å¤æ‚é—®é¢˜åˆ†è§£ï¼Œç³»ç»Ÿæ€§åˆ†æå†³ç­–
- ğŸ’° **æˆæœ¬åˆ†æ**: å®æ—¶ç›‘æ§APIè°ƒç”¨æˆæœ¬ï¼Œä¼˜åŒ–èµ„æºä½¿ç”¨

**å…³é”®æµ‹è¯•ç”¨ä¾‹**:
- âœ… æ™ºèƒ½é—®ç­”åŠ©æ‰‹çš„é—®é¢˜åˆ†ç±»å’Œå›ç­”è´¨é‡
- âœ… æ–‡æœ¬åˆ†æçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
- âœ… è§’è‰²æ‰®æ¼”çš„ä¸€è‡´æ€§å’Œä¸ªæ€§åŒ–ç¨‹åº¦
- âœ… å¤šæ­¥æ¨ç†çš„é€»è¾‘æ€§å’Œç»“è®ºè´¨é‡
- âœ… æ¡ä»¶å¯¹è¯æµçš„æƒ…æ„Ÿè¯†åˆ«å‡†ç¡®åº¦
- âœ… å†…å®¹ç”Ÿæˆçš„åˆ›é€ æ€§å’Œç»“æ„æ€§
- âœ… å¼‚æ­¥æ‰¹å¤„ç†çš„æ€§èƒ½å’Œç¨³å®šæ€§
- âœ… **Tokenä½¿ç”¨è¿½è¸ªçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§**
- âœ… **æˆæœ¬ä¼˜åŒ–ç­–ç•¥çš„æœ‰æ•ˆæ€§éªŒè¯**

## âš™ï¸ é…ç½®ä¸ç¯å¢ƒ

### API é…ç½®

æµ‹è¯•ä½¿ç”¨æœ¬åœ° API é…ç½®ï¼ˆ`src/config/api.py`ï¼‰ï¼š

```python
apis = {
    "local": {
        "base_url": "http://localhost:8212",
        "api_key": "sk-nsbaxS65nDJyGfA8wp5z7pbHxKUjEQBCpN5BKg7E19nLnOgL",
    }
}
```

### æ¨¡å‹é…ç½®

**é»˜è®¤æ¨¡å‹è®¾ç½®**:
- **æ¨¡å‹**: `gpt-4o-mini`ï¼ˆè½»é‡çº§ï¼Œé€‚åˆæµ‹è¯•ï¼‰
- **æ¸©åº¦**: `0.3-0.7`ï¼ˆæ ¹æ®æµ‹è¯•åœºæ™¯è°ƒæ•´ï¼‰
- **æœ€å¤§ä»¤ç‰Œ**: `100-1000`ï¼ˆæ ¹æ®æµ‹è¯•å¤æ‚åº¦ï¼‰
- **è¶…æ—¶**: `30ç§’`ï¼ˆé˜²æ­¢é•¿æ—¶é—´ç­‰å¾…ï¼‰

### ç¯å¢ƒå˜é‡

```bash
# å¯é€‰ï¼šè¦†ç›–é»˜è®¤é…ç½®
export LCEL_TEST_MODEL="gpt-4o-mini"
export LCEL_TEST_TEMPERATURE="0.3"
export LCEL_TEST_MAX_TOKENS="500"
export LCEL_TEST_TIMEOUT="30"
```

## ğŸ”§ è‡ªå®šä¹‰å’Œæ‰©å±•

### æ·»åŠ æ–°æµ‹è¯•

1. **åˆ›å»ºæµ‹è¯•æ–‡ä»¶**: `test_new_feature.py`
2. **å®ç°æµ‹è¯•ç±»**: ç»§æ‰¿ `unittest.TestCase`
3. **ç¼–å†™æµ‹è¯•æ–¹æ³•**: éµå¾ªå‘½åè§„èŒƒ
4. **æ³¨å†Œæµ‹è¯•**: åœ¨ `run_all_tests.py` ä¸­æ·»åŠ 

```python
def test_new_feature(self) -> None:
    """
    æµ‹è¯•æ–°åŠŸèƒ½çš„è¯¦ç»†æè¿°
    
    è¾“å…¥: æ— 
    è¾“å‡º: æ— 
    """
    print("\n=== æµ‹è¯•æ–°åŠŸèƒ½ ===")
    
    # 1. å‡†å¤‡æµ‹è¯•æ•°æ®
    test_input = "æµ‹è¯•è¾“å…¥"
    
    # 2. æ‰§è¡ŒåŠŸèƒ½
    result = new_feature_chain.invoke(test_input)
    
    # 3. éªŒè¯ç»“æœ
    self.assertEqual(result, expected_result)
    
    # 4. æ‰“å°æµ‹è¯•ä¿¡æ¯
    print(f"æµ‹è¯•ç»“æœ: {result}")
    print("âœ… æ–°åŠŸèƒ½æµ‹è¯•é€šè¿‡")
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•

```python
import time

def benchmark_feature(self):
    """æ€§èƒ½åŸºå‡†æµ‹è¯•æ¨¡æ¿"""
    test_data = ["æ•°æ®{}".format(i) for i in range(100)]
    
    start_time = time.time()
    results = feature_chain.batch(test_data)
    execution_time = time.time() - start_time
    
    print(f"æ‰§è¡Œæ—¶é—´: {execution_time:.4f}ç§’")
    print(f"æ¯ç§’å¤„ç†: {len(test_data) / execution_time:.2f}ä¸ª")
```

## ğŸ’° Tokenå¼€é”€åˆ†æä¸ä¼˜åŒ–

### Tokenä½¿ç”¨ç›‘æ§

æœ¬æµ‹è¯•å¥—ä»¶æä¾›äº†å®Œæ•´çš„tokenä½¿ç”¨è¿½è¸ªåŠŸèƒ½ï¼Œå¸®åŠ©ä½ å‡†ç¡®ç›‘æ§AIåº”ç”¨çš„æˆæœ¬ï¼š

#### å¿«é€Ÿå¼€å§‹Tokenç›‘æ§

```bash
# è¿è¡ŒåŒ…å«tokenè¿½è¸ªçš„æµ‹è¯•
python -m unittest unitests.test_lcel.test_chatopenai_applications.TestChatOpenAIApplications.test_content_generation_with_token_tracking_v2 -v

# è¿è¡Œè¯¦ç»†çš„åˆ†æ­¥tokenåˆ†æ
python -m unittest unitests.test_lcel.test_chatopenai_applications.TestChatOpenAIApplications.test_content_generation_step_by_step_tokens -v
```

### æˆæœ¬åˆ†æåŸºå‡†

åŸºäºå®é™…æµ‹è¯•çš„tokenæ¶ˆè€—åŸºå‡†æ•°æ®ï¼š

| åº”ç”¨åœºæ™¯ | è¾“å…¥Tokens | è¾“å‡ºTokens | æ€»è®¡Tokens | æ•ˆç‡æ¯” | æˆæœ¬ä¼°ç®—* |
|----------|------------|------------|------------|---------|-----------|
| æ™ºèƒ½é—®ç­” | 15-30 | 50-150 | 65-180 | 3.3x | $0.001-0.003 |
| æ–‡æœ¬åˆ†æ | 100-200 | 200-400 | 300-600 | 2.5x | $0.005-0.010 |
| å†…å®¹ç”Ÿæˆ | 25-50 | 300-800 | 325-850 | 12x | $0.005-0.015 |
| å¤šæ­¥æ¨ç† | 200-400 | 500-1200 | 700-1600 | 2.8x | $0.010-0.025 |
| è§’è‰²å¯¹è¯ | 50-100 | 150-300 | 200-400 | 2.5x | $0.003-0.008 |

*åŸºäºgpt-4o-miniå®šä»·ï¼šè¾“å…¥$0.15/1M tokensï¼Œè¾“å‡º$0.60/1M tokens

### ä¸‰ç§Tokenè¿½è¸ªæ–¹æ³•å¯¹æ¯”

#### ğŸ¯ æ–¹æ³•é€‰æ‹©æŒ‡å—

| åœºæ™¯ | æ¨èæ–¹æ³• | åŸå›  | ç¤ºä¾‹ç”¨æ³• |
|------|----------|------|----------|
| **ç”Ÿäº§ç›‘æ§** | Context Manager | ç®€æ´ã€è‡ªåŠ¨èšåˆ | æ—¥å¸¸æˆæœ¬ç›‘æ§ |
| **æ€§èƒ½è°ƒä¼˜** | åˆ†æ­¥å®æ—¶è¿½è¸ª | è¯¦ç»†åˆ†ææ¯æ­¥ | è¯†åˆ«æˆæœ¬çƒ­ç‚¹ |
| **å¤æ‚ç®¡é“** | å†…åµŒå¼è¿½è¸ª | ç»“æœåŒ…å«tokenä¿¡æ¯ | å¤šçº§ç®¡é“åˆ†æ |

#### æ€§èƒ½å¼€é”€å¯¹æ¯”

```python
# åŸºå‡†æµ‹è¯•ï¼š1000æ¬¡è°ƒç”¨çš„å¼€é”€
æ–¹æ³•1 (å†…åµŒå¼): +12ms å¹³å‡å»¶è¿Ÿ, +2MB å†…å­˜
æ–¹æ³•2 (Context Manager): +3ms å¹³å‡å»¶è¿Ÿ, +0.5MB å†…å­˜  â­ æ¨è
æ–¹æ³•3 (åˆ†æ­¥è¿½è¸ª): +8ms å¹³å‡å»¶è¿Ÿ, +1MB å†…å­˜
```

### æˆæœ¬ä¼˜åŒ–ç­–ç•¥

#### 1. æ¨¡å‹é€‰æ‹©ä¼˜åŒ–

```python
# æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©åˆé€‚æ¨¡å‹
models_by_cost = {
    "simple_qa": "gpt-4o-mini",        # æœ€ä¾¿å®œï¼Œé€‚åˆç®€å•é—®ç­”
    "content_gen": "gpt-4o",           # å¹³è¡¡æ€§ä»·æ¯”ï¼Œå†…å®¹ç”Ÿæˆ
    "complex_reasoning": "gpt-4-turbo" # æœ€è´µä½†æœ€å¼ºï¼Œå¤æ‚æ¨ç†
}

# åŠ¨æ€æ¨¡å‹é€‰æ‹©
def choose_model(task_complexity: str) -> ChatOpenAI:
    model_name = models_by_cost.get(task_complexity, "gpt-4o-mini")
    return ChatOpenAI(model=model_name, temperature=0.3)
```

#### 2. Promptä¼˜åŒ–æŠ€å·§

```python
# âŒ ä½æ•ˆpromptï¼šå†—é•¿ã€é‡å¤
inefficient_prompt = """
è¯·è¯¦ç»†åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºç§¯ææƒ…æ„Ÿã€æ¶ˆææƒ…æ„Ÿã€ä¸­æ€§æƒ…æ„Ÿï¼Œ
åŒæ—¶è¯·æä¾›è¯¦ç»†çš„åˆ†æè¿‡ç¨‹å’Œç†ç”±ï¼Œå¹¶ç»™å‡ºç½®ä¿¡åº¦è¯„åˆ†...
æ–‡æœ¬ï¼š{text}
"""

# âœ… é«˜æ•ˆpromptï¼šç®€æ´ã€æ˜ç¡®
efficient_prompt = """
åˆ†ææ–‡æœ¬æƒ…æ„Ÿï¼š{text}
è¾“å‡ºæ ¼å¼ï¼šæƒ…æ„Ÿ(ç§¯æ/æ¶ˆæ/ä¸­æ€§), ç½®ä¿¡åº¦(0-1), ç†ç”±(ä¸€å¥è¯)
"""

# èŠ‚çœtokenæ•ˆæœï¼šåŸprompt 45 tokens â†’ ä¼˜åŒ–å 20 tokens (55%èŠ‚çœ)
```

#### 3. æ‰¹å¤„ç†æˆæœ¬ä¼˜åŒ–

```python
# å•ç‹¬å¤„ç† vs æ‰¹å¤„ç†çš„æˆæœ¬å¯¹æ¯”
documents = [f"æ–‡æ¡£{i}" for i in range(100)]

# âŒ å•ç‹¬å¤„ç†ï¼š100æ¬¡APIè°ƒç”¨
total_cost = 0
for doc in documents:
    with get_usage_metadata_callback() as cb:
        result = chain.invoke({"text": doc})
        cost = calculate_cost(cb.usage_metadata)
        total_cost += cost
print(f"å•ç‹¬å¤„ç†æ€»æˆæœ¬: ${total_cost:.4f}")

# âœ… æ‰¹å¤„ç†ï¼š1æ¬¡APIè°ƒç”¨
with get_usage_metadata_callback() as cb:
    results = chain.batch([{"text": doc} for doc in documents])
    batch_cost = calculate_cost(cb.usage_metadata)
print(f"æ‰¹å¤„ç†æ€»æˆæœ¬: ${batch_cost:.4f}")
print(f"èŠ‚çœæˆæœ¬: {((total_cost - batch_cost) / total_cost * 100):.1f}%")

# å…¸å‹èŠ‚çœï¼š30-50%çš„æˆæœ¬é™ä½
```

#### 4. ç¼“å­˜ç­–ç•¥

```python
import functools
from typing import Dict, Any

@functools.lru_cache(maxsize=1000)
def cached_chain_invoke(input_hash: str, input_data: str) -> str:
    """å¸¦ç¼“å­˜çš„é“¾è°ƒç”¨ï¼Œé¿å…é‡å¤è®¡ç®—"""
    return chain.invoke({"text": input_data})

# ä½¿ç”¨ç¤ºä¾‹
def smart_invoke(text: str) -> str:
    text_hash = hash(text)
    return cached_chain_invoke(text_hash, text)

# ç¼“å­˜å‘½ä¸­ç‡ï¼šå…¸å‹åº”ç”¨å¯è¾¾åˆ°20-40%çš„ç¼“å­˜å‘½ä¸­
```

### å®æ—¶æˆæœ¬ç›‘æ§

#### æˆæœ¬è®¡ç®—å·¥å…·

```python
def calculate_cost(usage_metadata: Dict[str, Any], model: str = "gpt-4o-mini") -> float:
    """
    è®¡ç®—APIè°ƒç”¨æˆæœ¬
    
    è¾“å…¥: 
        usage_metadata: tokenä½¿ç”¨æ•°æ®
        model: æ¨¡å‹åç§°
    è¾“å‡º: 
        æˆæœ¬ï¼ˆç¾å…ƒï¼‰
    """
    # gpt-4o-mini å®šä»· (2024å¹´)
    pricing = {
        "gpt-4o-mini": {
            "input": 0.15 / 1_000_000,   # $0.15 per 1M input tokens
            "output": 0.60 / 1_000_000,  # $0.60 per 1M output tokens
        },
        "gpt-4o": {
            "input": 2.50 / 1_000_000,   # $2.50 per 1M input tokens  
            "output": 10.00 / 1_000_000, # $10.00 per 1M output tokens
        }
    }
    
    model_pricing = pricing.get(model, pricing["gpt-4o-mini"])
    total_cost = 0
    
    for model_name, usage in usage_metadata.items():
        input_cost = usage.get('input_tokens', 0) * model_pricing['input']
        output_cost = usage.get('output_tokens', 0) * model_pricing['output']
        total_cost += input_cost + output_cost
    
    return total_cost

# ä½¿ç”¨ç¤ºä¾‹
with get_usage_metadata_callback() as cb:
    result = expensive_chain.invoke(input_data)
    cost = calculate_cost(cb.usage_metadata, "gpt-4o")
    print(f"æœ¬æ¬¡è°ƒç”¨æˆæœ¬: ${cost:.6f}")
```

#### æˆæœ¬é¢„è­¦ç³»ç»Ÿ

```python
class CostMonitor:
    """æˆæœ¬ç›‘æ§å’Œé¢„è­¦ç³»ç»Ÿ"""
    
    def __init__(self, daily_budget: float = 10.0):
        self.daily_budget = daily_budget
        self.daily_cost = 0.0
        self.call_count = 0
    
    def track_call(self, usage_metadata: Dict[str, Any], model: str):
        """è¿½è¸ªå•æ¬¡è°ƒç”¨æˆæœ¬"""
        cost = calculate_cost(usage_metadata, model)
        self.daily_cost += cost
        self.call_count += 1
        
        # é¢„è­¦æ£€æŸ¥
        if self.daily_cost > self.daily_budget * 0.8:
            print(f"âš ï¸  æˆæœ¬é¢„è­¦ï¼šå·²ä½¿ç”¨ ${self.daily_cost:.4f} / ${self.daily_budget}")
        
        if self.daily_cost > self.daily_budget:
            print(f"ğŸš¨ é¢„ç®—è¶…æ”¯ï¼š${self.daily_cost:.4f} > ${self.daily_budget}")
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "daily_cost": self.daily_cost,
            "call_count": self.call_count,
            "avg_cost_per_call": self.daily_cost / max(self.call_count, 1),
            "budget_usage": self.daily_cost / self.daily_budget * 100
        }

# ä½¿ç”¨ç¤ºä¾‹
monitor = CostMonitor(daily_budget=5.0)

with get_usage_metadata_callback() as cb:
    result = chain.invoke(input_data)
    monitor.track_call(cb.usage_metadata, "gpt-4o-mini")

print(f"æˆæœ¬ç»Ÿè®¡: {monitor.get_stats()}")
```

### æœ€ä½³å®è·µæ€»ç»“

#### âœ… æ¨èåšæ³•

1. **ä½¿ç”¨Context Managerè¿½è¸ª** - æ—¥å¸¸ç›‘æ§çš„æœ€ä½³é€‰æ‹©
2. **Promptå·¥ç¨‹ä¼˜åŒ–** - å‡å°‘ä¸å¿…è¦çš„tokenæ¶ˆè€—
3. **åˆç†é€‰æ‹©æ¨¡å‹** - æ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŒ¹é…æ¨¡å‹èƒ½åŠ›
4. **æ‰¹å¤„ç†ä¼˜åŒ–** - å¤§é‡æ•°æ®å¤„ç†æ—¶ä¼˜å…ˆä½¿ç”¨æ‰¹å¤„ç†
5. **å®æ–½ç¼“å­˜ç­–ç•¥** - é¿å…é‡å¤è®¡ç®—ç›¸åŒå†…å®¹
6. **è®¾ç½®é¢„ç®—é¢„è­¦** - é˜²æ­¢æ„å¤–çš„é«˜é¢è´¹ç”¨

#### âŒ é¿å…çš„åšæ³•

1. **å¿½ç•¥tokenç›‘æ§** - å¯èƒ½å¯¼è‡´æ„å¤–é«˜é¢è´¹ç”¨
2. **è¿‡åº¦å†—é•¿çš„prompt** - ä¸å¿…è¦çš„tokenæµªè´¹
3. **æ€»æ˜¯ä½¿ç”¨æœ€å¼ºæ¨¡å‹** - æˆæœ¬è¿‡é«˜ä¸”ä¸å¿…è¦
4. **å¿½ç•¥ç¼“å­˜æœºä¼š** - é‡å¤è®¡ç®—å¢åŠ æˆæœ¬
5. **ç¼ºå°‘æˆæœ¬é¢„è­¦** - æ— æ³•åŠæ—¶å‘ç°å¼‚å¸¸æ¶ˆè€—

## ğŸ“Š æ€§èƒ½åŸºå‡†å’Œç›‘æ§

### æµ‹è¯•æ€§èƒ½åŸºå‡†

åŸºäºå½“å‰æµ‹è¯•ç»“æœçš„æ€§èƒ½æŒ‡æ ‡ï¼š

| åŠŸèƒ½æ¨¡å— | å¹³å‡æ‰§è¡Œæ—¶é—´ | å†…å­˜ä½¿ç”¨ | å¹¶å‘èƒ½åŠ› | ç¨³å®šæ€§ |
|----------|--------------|----------|----------|--------|
| åŸºç¡€ç»„åˆ | 45ms | ä½ | é«˜ | 99.9% |
| è¯­æ³•æ“ä½œç¬¦ | 40ms | ä½ | é«˜ | 99.9% |
| ç±»å‹è½¬æ¢ | 55ms | ä¸­ | é«˜ | 99.8% |
| å¼‚æ­¥æ“ä½œ | 120ms | ä¸­ | æé«˜ | 99.7% |
| æµå¼ä¼ è¾“ | 200ms+ | ä½ | é«˜ | 99.5% |
| å¹¶è¡Œæ‰§è¡Œ | 75ms | ä¸­ | æé«˜ | 99.8% |
| é”™è¯¯å¤„ç† | 50ms | ä½ | é«˜ | 99.9% |

### æ€§èƒ½ç›‘æ§å‘½ä»¤

```bash
# æ€§èƒ½åˆ†ææ¨¡å¼
python -m cProfile -o profile.stats unitests/test_lcel/run_all_tests.py

# å†…å­˜ä½¿ç”¨ç›‘æ§
python -m memory_profiler unitests/test_lcel/run_all_tests.py

# å¹¶å‘æ€§èƒ½æµ‹è¯•
python unitests/test_lcel/run_all_tests.py --tests parallel async
```

## ğŸš¦ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. API è¿æ¥é—®é¢˜
```
âŒ é”™è¯¯: Connection refused to localhost:8212
```
**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥æœ¬åœ° API æœåŠ¡æ˜¯å¦å¯åŠ¨
- éªŒè¯ `src/config/api.py` ä¸­çš„é…ç½®
- å°è¯•ä½¿ç”¨ä¸åŒçš„ç«¯å£æˆ–è¿œç¨‹ API

#### 2. å¼‚æ­¥æµ‹è¯•è¶…æ—¶
```
âŒ é”™è¯¯: asyncio.TimeoutError after 30 seconds
```
**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥ç½‘ç»œè¿æ¥ç¨³å®šæ€§
- å¢åŠ è¶…æ—¶æ—¶é—´é…ç½®
- ä½¿ç”¨æœ¬åœ°æ¨¡å‹å‡å°‘ç½‘ç»œä¾èµ–

#### 3. ä¾èµ–å®‰è£…é—®é¢˜
```
âŒ é”™è¯¯: ModuleNotFoundError: No module named 'langchain_core'
```
**è§£å†³æ–¹æ¡ˆ**:
```bash
# é‡æ–°å®‰è£…ä¾èµ–
source .venv/bin/activate
uv add langchain-openai langchain-core
pip install --upgrade langchain-core
```

#### 4. ç±»å‹è½¬æ¢å¤±è´¥
```
âŒ é”™è¯¯: 'dict' object has no attribute 'invoke'
```
**è§£å†³æ–¹æ¡ˆ**:
- ç¡®ä¿å­—å…¸åœ¨ LCEL è¡¨è¾¾å¼ä¸­ä½¿ç”¨ï¼ˆä¼šè‡ªåŠ¨è½¬æ¢ï¼‰
- ä¸è¦ç›´æ¥å¯¹å­—å…¸è°ƒç”¨ `invoke()` æ–¹æ³•
- ä½¿ç”¨ `RunnableParallel(dict)` æ˜¾å¼è½¬æ¢

### è°ƒè¯•æŠ€å·§

#### å¯ç”¨è¯¦ç»†è¾“å‡º
```bash
# è¯¦ç»†æµ‹è¯•è¾“å‡º
python unitests/test_lcel/run_all_tests.py --tests basic -v

# å•ç‹¬è¿è¡Œå¤±è´¥çš„æµ‹è¯•
python -m unittest unitests.test_lcel.test_basic_composition.TestLCELBasicComposition.test_specific_method -v
```

#### è°ƒè¯•ä»£ç æ¨¡æ¿
```python
import traceback
import logging

# å¯ç”¨è°ƒè¯•æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)

try:
    result = chain.invoke(test_input)
except Exception as e:
    print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
    print(f"é”™è¯¯ä¿¡æ¯: {e}")
    traceback.print_exc()
```

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
unitests/test_lcel/
â”œâ”€â”€ README.md                    # ğŸ“š é¡¹ç›®æ–‡æ¡£ï¼ˆæœ¬æ–‡ä»¶ï¼‰
â”œâ”€â”€ __init__.py                  # ğŸ“¦ åŒ…åˆå§‹åŒ–
â”œâ”€â”€ run_all_tests.py            # ğŸš€ ä¸»æµ‹è¯•è¿è¡Œå™¨
â”‚
â”œâ”€â”€ test_basic_composition.py    # ğŸ§© åŸºç¡€ç»„åˆåŠŸèƒ½æµ‹è¯•
â”œâ”€â”€ test_syntax_operators.py    # âš¡ è¯­æ³•æ“ä½œç¬¦æµ‹è¯•  
â”œâ”€â”€ test_type_coercion.py       # ğŸ”„ ç±»å‹è½¬æ¢æµ‹è¯•
â”œâ”€â”€ test_async_operations.py    # ğŸ”€ å¼‚æ­¥æ“ä½œæµ‹è¯•
â”œâ”€â”€ test_streaming.py           # ğŸ“¡ æµå¼ä¼ è¾“æµ‹è¯•
â”œâ”€â”€ test_parallel_execution.py  # ğŸš€ å¹¶è¡Œæ‰§è¡Œæµ‹è¯•
â”œâ”€â”€ test_error_handling.py      # ğŸ›¡ï¸ é”™è¯¯å¤„ç†æµ‹è¯•
â””â”€â”€ test_chatopenai_applications.py  # ğŸ¤– ChatOpenAIåº”ç”¨åœºæ™¯æµ‹è¯•
```

### æ–‡ä»¶è¯´æ˜

- **`run_all_tests.py`**: ä¸»æµ‹è¯•è¿è¡Œå™¨ï¼Œæ”¯æŒæ‰¹é‡æ‰§è¡Œã€è¯¦ç»†æŠ¥å‘Š
- **æµ‹è¯•æ¨¡å—**: æ¯ä¸ªæ–‡ä»¶æµ‹è¯• LCEL çš„ç‰¹å®šåŠŸèƒ½é¢†åŸŸï¼ŒåŒ…æ‹¬ä¸ChatOpenAIç»“åˆçš„å®é™…åº”ç”¨
- **`__init__.py`**: åŒ…é…ç½®ï¼Œå¯¼å…¥å¿…è¦çš„æ¨¡å—å’Œå‡½æ•°

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- [LangChain LCEL å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/docs/expression_language/)
- [LangChain Core API å‚è€ƒ](https://api.python.langchain.com/en/latest/langchain_core.html)
- [LangChain Runnable æ¥å£æ–‡æ¡£](https://python.langchain.com/docs/expression_language/interface)

### Python ç›¸å…³
- [Python asyncio å¼‚æ­¥ç¼–ç¨‹](https://docs.python.org/3/library/asyncio.html)
- [Python unittest æµ‹è¯•æ¡†æ¶](https://docs.python.org/3/library/unittest.html)
- [Python ç±»å‹æ³¨è§£æŒ‡å—](https://docs.python.org/3/library/typing.html)

### æœ€ä½³å®è·µ
- [LCEL æœ€ä½³å®è·µæŒ‡å—](https://python.langchain.com/docs/expression_language/cookbook)
- [å¼‚æ­¥ç¼–ç¨‹æœ€ä½³å®è·µ](https://docs.python.org/3/library/asyncio-dev.html)
- [Python æµ‹è¯•æœ€ä½³å®è·µ](https://docs.python-guide.org/writing/tests/)

**å¼€å§‹ä½¿ç”¨**:
```bash
# å…‹éš†å¹¶è¿è¡Œ
git clone <your-repo>
cd <your-repo>
source .venv/bin/activate
python unitests/test_lcel/run_all_tests.py
```