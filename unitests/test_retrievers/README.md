# LangChain æ£€ç´¢å™¨åŠŸèƒ½è¯¦è§£ä¸æµ‹è¯•

æœ¬æµ‹è¯•å¥—ä»¶æ·±å…¥æµ‹è¯•LangChainæ£€ç´¢å™¨çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œæ¶µç›–å‘é‡å­˜å‚¨æ£€ç´¢ã€å¤šæŸ¥è¯¢æ£€ç´¢ã€ä¸Šä¸‹æ–‡å‹ç¼©ç­‰å…³é”®æŠ€æœ¯ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»è¿™äº›LangChainæ£€ç´¢å™¨ç»„ä»¶çš„åŠŸèƒ½ã€ç”¨æ³•å’Œæœ€ä½³å®è·µã€‚

## ç›®å½•ç»“æ„

```
test_retrievers/
â”œâ”€â”€ README.md                       # æœ¬æ–‡ä»¶ï¼ŒLangChainæ£€ç´¢å™¨åŠŸèƒ½è¯¦è§£
â”œâ”€â”€ run_tests.py                   # æµ‹è¯•è¿è¡Œè„šæœ¬
â”œâ”€â”€ test_basic_retrievers.py       # åŸºç¡€æ£€ç´¢å™¨åŠŸèƒ½æµ‹è¯•
â”œâ”€â”€ test_multiquery_retrievers.py  # å¤šæŸ¥è¯¢æ£€ç´¢å™¨æµ‹è¯•
â”œâ”€â”€ test_compression_retrievers.py # ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨æµ‹è¯•
â””â”€â”€ test_search_strategies.py      # æœç´¢ç­–ç•¥å’Œå‚æ•°æµ‹è¯•
```

## LangChain æ£€ç´¢å™¨æ ¸å¿ƒç»„ä»¶åŠŸèƒ½è¯¦è§£

### 1. åŸºç¡€å‘é‡å­˜å‚¨æ£€ç´¢å™¨ (`VectorStoreRetriever`)

å‘é‡å­˜å‚¨æ£€ç´¢å™¨æ˜¯æœ€åŸºç¡€çš„æ£€ç´¢å™¨ç±»å‹ï¼Œå®ƒä½¿ç”¨å‘é‡å­˜å‚¨æ¥æ£€ç´¢æ–‡æ¡£ã€‚

#### 1.1 æ ¸å¿ƒæ–¹æ³•

**`as_retriever(search_type="similarity", search_kwargs={})`**
- **åŠŸèƒ½**: ä»å‘é‡å­˜å‚¨åˆ›å»ºæ£€ç´¢å™¨
- **è¾“å…¥**: æœç´¢ç±»å‹å’Œæœç´¢å‚æ•°
- **è¾“å‡º**: VectorStoreRetrieverå®ä¾‹
- **åº”ç”¨åœºæ™¯**: 
  - åŸºç¡€æ–‡æ¡£æ£€ç´¢ï¼šæ ¹æ®ç›¸ä¼¼æ€§æŸ¥æ‰¾ç›¸å…³æ–‡æ¡£
  - çŸ¥è¯†åº“é—®ç­”ï¼šæ£€ç´¢ç›¸å…³çŸ¥è¯†è¿›è¡Œé—®ç­”
  - æ–‡æ¡£æ¨èï¼šåŸºäºå†…å®¹ç›¸ä¼¼æ€§æ¨èæ–‡æ¡£

**ä¸»è¦æœç´¢ç±»å‹**:
- `similarity`: ç›¸ä¼¼æ€§æœç´¢ï¼ˆé»˜è®¤ï¼‰
- `mmr`: æœ€å¤§è¾¹é™…ç›¸å…³æ€§æœç´¢ï¼Œå‡å°‘ç»“æœå†—ä½™
- `similarity_score_threshold`: åŸºäºç›¸ä¼¼æ€§åˆ†æ•°é˜ˆå€¼çš„æœç´¢

```python
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

# åˆ›å»ºå‘é‡å­˜å‚¨
vectorstore = FAISS.from_documents(documents, OpenAIEmbeddings())

# åˆ›å»ºåŸºç¡€æ£€ç´¢å™¨
retriever = vectorstore.as_retriever()

# åˆ›å»ºMMRæ£€ç´¢å™¨
mmr_retriever = vectorstore.as_retriever(search_type="mmr")

# åˆ›å»ºé˜ˆå€¼æ£€ç´¢å™¨
threshold_retriever = vectorstore.as_retriever(
    search_type="similarity_score_threshold",
    search_kwargs={"score_threshold": 0.5}
)
```

#### 1.2 æœç´¢å‚æ•°é…ç½®

**`search_kwargs` å¸¸ç”¨å‚æ•°**:
- `k`: è¿”å›æ–‡æ¡£æ•°é‡ï¼ˆé»˜è®¤4ï¼‰
- `score_threshold`: ç›¸ä¼¼æ€§åˆ†æ•°é˜ˆå€¼
- `fetch_k`: MMRæœç´¢ä¸­è·å–çš„å€™é€‰æ–‡æ¡£æ•°
- `lambda_mult`: MMRå¤šæ ·æ€§å‚æ•°

```python
# é™åˆ¶è¿”å›æ–‡æ¡£æ•°é‡
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# è®¾ç½®ç›¸ä¼¼æ€§é˜ˆå€¼
retriever = vectorstore.as_retriever(
    search_type="similarity_score_threshold",
    search_kwargs={"score_threshold": 0.7}
)

# MMRå‚æ•°é…ç½®
retriever = vectorstore.as_retriever(
    search_type="mmr",
    search_kwargs={
        "k": 5,
        "fetch_k": 20,
        "lambda_mult": 0.5
    }
)
```

### 2. å¤šæŸ¥è¯¢æ£€ç´¢å™¨ (`MultiQueryRetriever`)

å¤šæŸ¥è¯¢æ£€ç´¢å™¨é€šè¿‡LLMç”Ÿæˆå¤šä¸ªä¸åŒè§†è§’çš„æŸ¥è¯¢ï¼Œç„¶ååˆå¹¶æ£€ç´¢ç»“æœï¼Œä»¥æé«˜æ£€ç´¢çš„å…¨é¢æ€§ã€‚

#### 2.1 æ ¸å¿ƒåŠŸèƒ½

**è‡ªåŠ¨æŸ¥è¯¢ç”Ÿæˆ**:
- ä½¿ç”¨LLMä»ç”¨æˆ·æŸ¥è¯¢ç”Ÿæˆå¤šä¸ªä¸åŒè§†è§’çš„æŸ¥è¯¢
- å¯¹æ¯ä¸ªç”Ÿæˆçš„æŸ¥è¯¢è¿›è¡Œç‹¬ç«‹æ£€ç´¢
- åˆå¹¶å»é‡æ‰€æœ‰æ£€ç´¢ç»“æœ

**ä¼˜åŠ¿**:
- å…‹æœå•ä¸€æŸ¥è¯¢è¡¨è¾¾é™åˆ¶
- å‡å°‘å› æŸ¥è¯¢è¡¨è¿°ä¸å‡†ç¡®å¯¼è‡´çš„æ£€ç´¢é—æ¼
- æä¾›æ›´å…¨é¢çš„æ£€ç´¢ç»“æœ

```python
from langchain.retrievers.multi_query import MultiQueryRetriever
from langchain_openai import ChatOpenAI

# åˆ›å»ºå¤šæŸ¥è¯¢æ£€ç´¢å™¨
llm = ChatOpenAI(temperature=0)
retriever = MultiQueryRetriever.from_llm(
    retriever=vectorstore.as_retriever(),
    llm=llm
)

# ä½¿ç”¨æ£€ç´¢å™¨
docs = retriever.invoke("ä»€ä¹ˆæ˜¯ä»»åŠ¡åˆ†è§£çš„æ–¹æ³•ï¼Ÿ")
```

#### 2.2 è‡ªå®šä¹‰æŸ¥è¯¢ç”Ÿæˆ

å¯ä»¥é€šè¿‡è‡ªå®šä¹‰æç¤ºæ¨¡æ¿æ¥æ§åˆ¶æŸ¥è¯¢ç”Ÿæˆçš„è¡Œä¸ºï¼š

```python
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import BaseOutputParser

# è‡ªå®šä¹‰è¾“å‡ºè§£æå™¨
class LineListOutputParser(BaseOutputParser[List[str]]):
    def parse(self, text: str) -> List[str]:
        lines = text.strip().split("\n")
        return list(filter(None, lines))

# è‡ªå®šä¹‰æç¤ºæ¨¡æ¿
QUERY_PROMPT = PromptTemplate(
    input_variables=["question"],
    template="""ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ç”Ÿæˆ5ä¸ªä¸åŒç‰ˆæœ¬çš„ç”¨æˆ·é—®é¢˜ï¼Œ
    ä»¥ä¾¿ä»å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£ã€‚é€šè¿‡ä»ä¸åŒè§’åº¦ç”Ÿæˆé—®é¢˜ï¼Œ
    å¸®åŠ©ç”¨æˆ·å…‹æœåŸºäºè·ç¦»çš„ç›¸ä¼¼æ€§æœç´¢çš„å±€é™æ€§ã€‚
    è¯·ç”¨æ¢è¡Œç¬¦åˆ†éš”è¿™äº›æ›¿ä»£é—®é¢˜ã€‚
    åŸå§‹é—®é¢˜: {question}"""
)

# åˆ›å»ºè‡ªå®šä¹‰æ£€ç´¢å™¨
llm_chain = QUERY_PROMPT | llm | LineListOutputParser()
retriever = MultiQueryRetriever(
    retriever=vectorstore.as_retriever(),
    llm_chain=llm_chain,
    parser_key="lines"
)
```

### 3. ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨ (`ContextualCompressionRetriever`)

ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨é€šè¿‡å‹ç¼©å’Œè¿‡æ»¤æ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼Œåªè¿”å›ä¸æŸ¥è¯¢æœ€ç›¸å…³çš„å†…å®¹ã€‚

**ğŸ“– æœ¬èŠ‚å†…å®¹å¯¼èˆª**:
- 3.1 æ ¸å¿ƒç»„ä»¶æ¦‚è§ˆ
- **3.2 LLMChainFilter å·¥ä½œåŸç†è¯¦è§£** â­ *æ–°å¢*
- 3.3 å‹ç¼©å™¨ç®¡é“ä½¿ç”¨

#### 3.1 æ ¸å¿ƒç»„ä»¶

**æ–‡æ¡£å‹ç¼©å™¨ç±»å‹**:
- `LLMChainExtractor`: ä½¿ç”¨LLMæå–ç›¸å…³å†…å®¹
- `LLMChainFilter`: ä½¿ç”¨LLMè¿‡æ»¤æ— å…³æ–‡æ¡£
- `LLMListwiseRerank`: ä½¿ç”¨LLMé‡æ–°æ’åºæ–‡æ¡£
- `EmbeddingsFilter`: åŸºäºåµŒå…¥ç›¸ä¼¼æ€§è¿‡æ»¤

#### 3.2 LLMChainFilter å·¥ä½œåŸç†è¯¦è§£

LLMChainFilter æ˜¯ä¸€ä¸ªæ™ºèƒ½æ–‡æ¡£è¿‡æ»¤å™¨ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹çš„ç†è§£èƒ½åŠ›æ¥åˆ¤æ–­æ–‡æ¡£ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§ã€‚

**ğŸ” æ ¸å¿ƒå·¥ä½œæµç¨‹**:

1. **è¾“å…¥æ„é€ é˜¶æ®µ**
   - ä½¿ç”¨ `get_input` å‡½æ•°å°†æŸ¥è¯¢å’Œæ¯ä¸ªæ–‡æ¡£ç»„åˆæˆ LLM è¾“å…¥
   - é»˜è®¤ä¼šåˆ›å»ºåŒ…å«æŸ¥è¯¢å’Œæ–‡æ¡£å†…å®¹çš„æç¤ºè¯

2. **æ‰¹é‡ LLM æ¨ç†**
   - è°ƒç”¨ `llm_chain.batch()` åŒæ—¶å¤„ç†å¤šä¸ªæ–‡æ¡£
   - LLM åˆ†ææ¯ä¸ªæ–‡æ¡£ä¸æŸ¥è¯¢çš„è¯­ä¹‰ç›¸å…³æ€§

3. **ç»“æœè§£æä¸è¿‡æ»¤**
   - è§£æ LLM è¾“å‡ºä¸ºå¸ƒå°”å€¼ï¼ˆç›¸å…³/ä¸ç›¸å…³ï¼‰
   - åªä¿ç•™è¢«åˆ¤å®šä¸ºç›¸å…³çš„æ–‡æ¡£

**ğŸ’¡ å·¥ä½œç‰¹ç‚¹**:
- **è¯­ä¹‰ç†è§£**: åŸºäºæ·±åº¦è¯­è¨€ç†è§£ï¼Œä¸ä»…ä»…æ˜¯å…³é”®è¯åŒ¹é…
- **å†…å®¹ä¿æŒ**: åªåšè¿‡æ»¤ï¼Œä¸å‹ç¼©æ–‡æ¡£å†…å®¹
- **å‡†ç¡®æ€§é«˜**: ç›¸æ¯”ç®€å•çš„ç›¸ä¼¼åº¦è®¡ç®—ï¼Œåˆ¤æ–­æ›´å‡†ç¡®
- **æˆæœ¬è¾ƒé«˜**: éœ€è¦è°ƒç”¨ LLM APIï¼Œé€Ÿåº¦å’Œæˆæœ¬æ¯”åµŒå…¥è¿‡æ»¤å™¨é«˜

**ğŸ†š æ€§èƒ½å¯¹æ¯”**:

| å‹ç¼©å™¨ç±»å‹ | é€Ÿåº¦ | æˆæœ¬ | å‡†ç¡®æ€§ | é€‚ç”¨åœºæ™¯ |
|------------|------|------|--------|----------|
| **LLMChainFilter** | æ…¢ | é«˜ | å¾ˆé«˜ | ç²¾ç¡®è¿‡æ»¤ï¼Œè´¨é‡ä¼˜å…ˆ |
| **EmbeddingsFilter** | å¿« | ä½ | ä¸­ç­‰ | å¿«é€Ÿè¿‡æ»¤ï¼Œæ•ˆç‡ä¼˜å…ˆ |
| **LLMChainExtractor** | æ…¢ | é«˜ | é«˜ | å†…å®¹å‹ç¼©ï¼Œç²¾ç¡®æå– |

**ğŸ¯ æœ€ä½³åº”ç”¨åœºæ™¯**:
- éœ€è¦é«˜ç²¾åº¦æ–‡æ¡£è¿‡æ»¤çš„ RAG ç³»ç»Ÿ
- å¯¹å‡†ç¡®æ€§è¦æ±‚é«˜äºé€Ÿåº¦çš„çŸ¥è¯†é—®ç­”
- å¤æ‚è¯­ä¹‰åˆ¤æ–­çš„æ–‡æ¡£ç­›é€‰ä»»åŠ¡

```python
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import (
    LLMChainExtractor,
    LLMChainFilter,
    EmbeddingsFilter
)

# LLMæå–å™¨ - æå–ç›¸å…³å†…å®¹
llm = ChatOpenAI(temperature=0)
compressor = LLMChainExtractor.from_llm(llm)
compression_retriever = ContextualCompressionRetriever(
    base_compressor=compressor,
    base_retriever=retriever
)

# LLMè¿‡æ»¤å™¨ - ä½¿ç”¨è¯­è¨€æ¨¡å‹æ™ºèƒ½è¿‡æ»¤æ— å…³æ–‡æ¡£
filter_compressor = LLMChainFilter.from_llm(llm)
filter_retriever = ContextualCompressionRetriever(
    base_compressor=filter_compressor,
    base_retriever=retriever
)

# å®é™…ä½¿ç”¨ç¤ºä¾‹ï¼šè¿‡æ»¤æ•ˆæœå¯¹æ¯”
# ç›¸å…³æŸ¥è¯¢ - ä¼šä¿ç•™æ›´å¤šç›¸å…³æ–‡æ¡£
relevant_docs = filter_retriever.invoke("Ketanji Brown Jackson nomination")

# ä¸ç›¸å…³æŸ¥è¯¢ - ä¼šè¿‡æ»¤æ‰å¤§éƒ¨åˆ†æ— å…³æ–‡æ¡£  
irrelevant_docs = filter_retriever.invoke("cooking recipes and food preparation")

print(f"ç›¸å…³æŸ¥è¯¢ç»“æœæ•°: {len(relevant_docs)}")
print(f"ä¸ç›¸å…³æŸ¥è¯¢ç»“æœæ•°: {len(irrelevant_docs)}")
# é¢„æœŸ: relevant_docs æ•°é‡ > irrelevant_docs æ•°é‡

# åµŒå…¥è¿‡æ»¤å™¨ - åŸºäºç›¸ä¼¼æ€§è¿‡æ»¤
embeddings_filter = EmbeddingsFilter(
    embeddings=OpenAIEmbeddings(),
    similarity_threshold=0.76
)
embedding_retriever = ContextualCompressionRetriever(
    base_compressor=embeddings_filter,
    base_retriever=retriever
)
```

#### 3.3 å‹ç¼©å™¨ç®¡é“

å¯ä»¥ç»„åˆå¤šä¸ªå‹ç¼©å™¨å½¢æˆå¤„ç†ç®¡é“ï¼š

```python
from langchain.retrievers.document_compressors import DocumentCompressorPipeline
from langchain_community.document_transformers import EmbeddingsRedundantFilter
from langchain_text_splitters import CharacterTextSplitter

# åˆ›å»ºå¤„ç†ç®¡é“
splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0, separator=". ")
redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)
relevant_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)

# ç»„è£…ç®¡é“ï¼šåˆ†å‰² -> å»é‡ -> ç›¸å…³æ€§è¿‡æ»¤
pipeline_compressor = DocumentCompressorPipeline(
    transformers=[splitter, redundant_filter, relevant_filter]
)

compression_retriever = ContextualCompressionRetriever(
    base_compressor=pipeline_compressor,
    base_retriever=retriever
)
```

### 4. æ£€ç´¢å™¨æ€§èƒ½ä¼˜åŒ–

#### 4.1 æœç´¢ç­–ç•¥é€‰æ‹©

**ç›¸ä¼¼æ€§æœç´¢ vs MMR**:
- ç›¸ä¼¼æ€§æœç´¢ï¼šé€Ÿåº¦å¿«ï¼Œé€‚åˆç²¾ç¡®åŒ¹é…
- MMRæœç´¢ï¼šç»“æœå¤šæ ·åŒ–ï¼Œé¿å…å†—ä½™ï¼Œé€‚åˆæ¢ç´¢æ€§æŸ¥è¯¢

**é˜ˆå€¼è®¾ç½®**:
- é«˜é˜ˆå€¼ï¼ˆ0.8+ï¼‰ï¼šç²¾ç¡®åŒ¹é…ï¼Œç»“æœå°‘ä½†è´¨é‡é«˜
- ä¸­é˜ˆå€¼ï¼ˆ0.5-0.8ï¼‰ï¼šå¹³è¡¡ç²¾åº¦å’Œå¬å›ç‡
- ä½é˜ˆå€¼ï¼ˆ0.3-0.5ï¼‰ï¼šå¹¿æ³›åŒ¹é…ï¼Œç»“æœå¤šä½†å¯èƒ½æœ‰å™ªå£°

#### 4.2 æ‰¹é‡æ£€ç´¢ä¼˜åŒ–

```python
# å¼‚æ­¥æ‰¹é‡æ£€ç´¢
import asyncio

async def batch_retrieve(retriever, queries: List[str]):
    """æ‰¹é‡å¼‚æ­¥æ£€ç´¢"""
    tasks = [retriever.ainvoke(query) for query in queries]
    results = await asyncio.gather(*tasks)
    return results

# ç¼“å­˜æ£€ç´¢ç»“æœ
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_retrieve(query: str):
    """ç¼“å­˜æ£€ç´¢ç»“æœ"""
    return retriever.invoke(query)
```

## ä½¿ç”¨æœ€ä½³å®è·µ

### 1. æ£€ç´¢å™¨é€‰æ‹©æŒ‡å—

**åœºæ™¯1: ç²¾ç¡®é—®ç­”**
- ä½¿ç”¨åŸºç¡€ç›¸ä¼¼æ€§æ£€ç´¢ + é«˜é˜ˆå€¼
- é€‚åˆäº‹å®æŸ¥è¯¢ã€å®šä¹‰æŸ¥è¯¢

**åœºæ™¯2: æ¢ç´¢æ€§æœç´¢**
- ä½¿ç”¨MMRæ£€ç´¢æˆ–å¤šæŸ¥è¯¢æ£€ç´¢
- é€‚åˆå¼€æ”¾æ€§é—®é¢˜ã€ç ”ç©¶æ€§æŸ¥è¯¢

**åœºæ™¯3: é•¿æ–‡æ¡£å¤„ç†**
- ä½¿ç”¨ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨
- å‡å°‘æ— å…³å†…å®¹ï¼Œæé«˜LLMå¤„ç†æ•ˆç‡

**åœºæ™¯4: å®æ—¶åº”ç”¨**
- ä½¿ç”¨åµŒå…¥è¿‡æ»¤å™¨è€ŒéLLMå‹ç¼©å™¨
- å¹³è¡¡ç²¾åº¦å’Œé€Ÿåº¦

### 2. å‚æ•°è°ƒä¼˜å»ºè®®

**kå€¼è®¾ç½®**:
- é—®ç­”ç³»ç»Ÿï¼šk=3-5
- æ–‡æ¡£æ¨èï¼šk=10-20
- å†…å®¹ç”Ÿæˆï¼šk=5-10

**é˜ˆå€¼è®¾ç½®**:
- ä¸¥æ ¼åŒ¹é…ï¼šthreshold=0.8+
- ä¸€èˆ¬ç”¨é€”ï¼šthreshold=0.6-0.8
- å¹¿æ³›æœç´¢ï¼šthreshold=0.3-0.6

**MMRå‚æ•°**:
- å¤šæ ·æ€§ä¼˜å…ˆï¼šlambda_mult=0.3-0.5
- ç›¸å…³æ€§ä¼˜å…ˆï¼šlambda_mult=0.7-0.9
- å¹³è¡¡æ¨¡å¼ï¼šlambda_mult=0.5-0.7

### 3. é”™è¯¯å¤„ç†å’Œç›‘æ§

```python
import logging
from typing import Optional

# è®¾ç½®æ£€ç´¢å™¨æ—¥å¿—
logging.basicConfig()
logging.getLogger("langchain.retrievers").setLevel(logging.INFO)

def robust_retrieve(retriever, query: str, fallback_k: int = 10) -> List[Document]:
    """
    å¥å£®çš„æ£€ç´¢å‡½æ•°
    
    Args:
        retriever: æ£€ç´¢å™¨å®ä¾‹
        query: æŸ¥è¯¢å­—ç¬¦ä¸²
        fallback_k: é™çº§æ—¶çš„æ–‡æ¡£æ•°é‡
        
    Returns:
        æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
    """
    try:
        # å°è¯•æ­£å¸¸æ£€ç´¢
        docs = retriever.invoke(query)
        if not docs:
            # å¦‚æœæ²¡æœ‰ç»“æœï¼Œé™ä½é˜ˆå€¼é‡è¯•
            fallback_retriever = vectorstore.as_retriever(search_kwargs={"k": fallback_k})
            docs = fallback_retriever.invoke(query)
        return docs
    except Exception as e:
        logging.error(f"æ£€ç´¢å¤±è´¥: {e}")
        # è¿”å›ç©ºç»“æœæˆ–é»˜è®¤æ–‡æ¡£
        return []
```

## æ€§èƒ½åŸºå‡†æµ‹è¯•

æµ‹è¯•å¥—ä»¶åŒ…å«ä»¥ä¸‹æ€§èƒ½è¯„ä¼°ï¼š

1. **æ£€ç´¢å»¶è¿Ÿæµ‹è¯•**: ä¸åŒæ£€ç´¢å™¨çš„å“åº”æ—¶é—´å¯¹æ¯”
2. **æ£€ç´¢è´¨é‡æµ‹è¯•**: åŸºäºäººå·¥æ ‡æ³¨çš„ç›¸å…³æ€§è¯„ä¼°
3. **ç¼“å­˜æ•ˆæœæµ‹è¯•**: ç¼“å­˜å¯¹æ€§èƒ½æå‡çš„é‡åŒ–åˆ†æ
4. **æ‰¹é‡å¤„ç†æµ‹è¯•**: å¤§æ‰¹é‡æŸ¥è¯¢çš„å¤„ç†èƒ½åŠ›
5. **èµ„æºæ¶ˆè€—æµ‹è¯•**: å†…å­˜å’ŒCPUä½¿ç”¨æƒ…å†µç›‘æ§

## LLMChainFilter å®æˆ˜æŠ€å·§ ğŸ’¡

### ğŸ¯ ä¼˜åŒ–ç­–ç•¥

1. **æ¸©åº¦å‚æ•°è°ƒä¼˜**
   ```python
   # ä½æ¸©åº¦ç¡®ä¿ç¨³å®šçš„è¿‡æ»¤åˆ¤æ–­
   llm = ChatOpenAI(temperature=0.1)  # æ¨èå€¼ï¼š0.1-0.3
   filter_compressor = LLMChainFilter.from_llm(llm)
   ```

2. **è‡ªå®šä¹‰æç¤ºè¯ä¼˜åŒ–**
   ```python
   from langchain_core.prompts import PromptTemplate
   
   # è‡ªå®šä¹‰è¿‡æ»¤æç¤ºè¯
   custom_prompt = PromptTemplate.from_template("""
   æŸ¥è¯¢: {query}
   æ–‡æ¡£: {document}
   
   è¯·åˆ¤æ–­è¯¥æ–‡æ¡£æ˜¯å¦ä¸æŸ¥è¯¢ç›´æ¥ç›¸å…³ï¼Ÿ
   åªå›ç­”"æ˜¯"æˆ–"å¦"ã€‚
   """)
   
   filter_compressor = LLMChainFilter.from_llm(llm, prompt=custom_prompt)
   ```

3. **æ€§èƒ½ä¸æˆæœ¬å¹³è¡¡**
   ```python
   # æ··åˆç­–ç•¥ï¼šå…ˆç”¨å¿«é€Ÿè¿‡æ»¤ï¼Œå†ç”¨ç²¾ç¡®è¿‡æ»¤
   pipeline = DocumentCompressorPipeline([
       EmbeddingsFilter(similarity_threshold=0.3),  # åˆæ­¥è¿‡æ»¤
       LLMChainFilter.from_llm(llm)                # ç²¾ç¡®è¿‡æ»¤
   ])
   ```

### âš ï¸ æ³¨æ„äº‹é¡¹

1. **APIé…é¢ç®¡ç†**: å¤šæŸ¥è¯¢æ£€ç´¢å™¨å’ŒLLMå‹ç¼©å™¨ä¼šå¢åŠ APIè°ƒç”¨
2. **å»¶è¿Ÿè€ƒè™‘**: LLMå‹ç¼©å™¨ä¼šå¢åŠ æ£€ç´¢å»¶è¿Ÿ
3. **æˆæœ¬æ§åˆ¶**: æƒè¡¡æ£€ç´¢è´¨é‡å’ŒAPIæˆæœ¬
4. **ç»“æœç¼“å­˜**: å¯¹é¢‘ç¹æŸ¥è¯¢ä½¿ç”¨ç¼“å­˜æœºåˆ¶
5. **é™çº§ç­–ç•¥**: å‡†å¤‡æ£€ç´¢å¤±è´¥æ—¶çš„é™çº§æ–¹æ¡ˆ 