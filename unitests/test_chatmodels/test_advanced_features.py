"""
é«˜çº§åŠŸèƒ½æµ‹è¯•

æµ‹è¯•ChatOpenAIæ¨¡å‹çš„é«˜çº§åŠŸèƒ½ï¼ŒåŒ…æ‹¬å·¥å…·è°ƒç”¨ã€ç»“æ„åŒ–è¾“å‡ºã€æ‰¹å¤„ç†ç­‰
"""

import unittest
import json
import re
from typing import List, Dict, Any, Optional, Union
from pydantic import BaseModel, Field
from typing_extensions import Annotated, TypedDict

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage
from langchain_core.tools import tool
from langchain_core.output_parsers import PydanticToolsParser, PydanticOutputParser
from langchain_core.prompts import ChatPromptTemplate

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../../src'))

from src.config.api import apis


# å®šä¹‰æµ‹è¯•ç”¨çš„Pydanticæ¨¡å‹
class WeatherInfo(BaseModel):
    """å¤©æ°”ä¿¡æ¯æ¨¡å‹"""
    location: str = Field(description="åœ°ç‚¹åç§°")
    temperature: float = Field(description="æ¸©åº¦ï¼ˆæ‘„æ°åº¦ï¼‰")
    humidity: int = Field(description="æ¹¿åº¦ç™¾åˆ†æ¯”")
    description: str = Field(description="å¤©æ°”æè¿°")


class MathResult(BaseModel):
    """æ•°å­¦è®¡ç®—ç»“æœæ¨¡å‹"""
    operation: str = Field(description="æ‰§è¡Œçš„æ•°å­¦è¿ç®—")
    result: float = Field(description="è®¡ç®—ç»“æœ")
    explanation: str = Field(description="è®¡ç®—è¿‡ç¨‹è¯´æ˜")


class Joke(BaseModel):
    """ç¬‘è¯æ¨¡å‹"""
    setup: str = Field(description="ç¬‘è¯çš„é“ºå«")
    punchline: str = Field(description="ç¬‘è¯çš„åŒ…è¢±")
    rating: Optional[int] = Field(default=None, description="æç¬‘ç¨‹åº¦ï¼Œ1-10åˆ†")


class ConversationalResponse(BaseModel):
    """å¯¹è¯å›å¤æ¨¡å‹"""
    response: str = Field(description="å¯¹ç”¨æˆ·æŸ¥è¯¢çš„å¯¹è¯å¼å›å¤")


class MultiResponse(BaseModel):
    """å¤šç±»å‹å“åº”æ¨¡å‹"""
    final_output: Union[Joke, ConversationalResponse]


class Person(BaseModel):
    """äººå‘˜ä¿¡æ¯æ¨¡å‹"""
    name: str = Field(description="äººå‘˜å§“å")
    age: int = Field(description="äººå‘˜å¹´é¾„")
    height_in_meters: float = Field(description="èº«é«˜ï¼ˆç±³ï¼‰")


class People(BaseModel):
    """å¤šäººä¿¡æ¯æ¨¡å‹"""
    people: List[Person]


# TypedDictå®šä¹‰
class JokeDict(TypedDict):
    """ç¬‘è¯å­—å…¸ç±»å‹"""
    setup: Annotated[str, ..., "ç¬‘è¯çš„é“ºå«"]
    punchline: Annotated[str, ..., "ç¬‘è¯çš„åŒ…è¢±"]
    rating: Annotated[Optional[int], None, "æç¬‘ç¨‹åº¦ï¼Œ1-10åˆ†"]


class WeatherDict(TypedDict):
    """å¤©æ°”å­—å…¸ç±»å‹"""
    location: Annotated[str, ..., "åœ°ç‚¹åç§°"]
    temperature: Annotated[float, ..., "æ¸©åº¦ï¼ˆæ‘„æ°åº¦ï¼‰"]
    humidity: Annotated[int, ..., "æ¹¿åº¦ç™¾åˆ†æ¯”"]
    description: Annotated[str, ..., "å¤©æ°”æè¿°"]


# å®šä¹‰æµ‹è¯•ç”¨çš„å·¥å…·
@tool
def get_weather(location: str) -> Dict[str, Any]:
    """
    è·å–æŒ‡å®šåœ°ç‚¹çš„å¤©æ°”ä¿¡æ¯
    
    Args:
        location: åœ°ç‚¹åç§°
        
    Returns:
        Dict[str, Any]: å¤©æ°”ä¿¡æ¯å­—å…¸
    """
    return {
        "location": location,
        "temperature": 22.5,
        "humidity": 65,
        "description": "æ™´æœ—"
    }


@tool  
def calculate_math(expression: str) -> Dict[str, Any]:
    """
    è®¡ç®—æ•°å­¦è¡¨è¾¾å¼
    
    Args:
        expression: æ•°å­¦è¡¨è¾¾å¼å­—ç¬¦ä¸²
        
    Returns:
        Dict[str, Any]: è®¡ç®—ç»“æœå­—å…¸
    """
    try:
        result = eval(expression)  # ä»…ç”¨äºæµ‹è¯•ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦å®‰å…¨çš„æ•°å­¦è§£æå™¨
        return {
            "operation": expression,
            "result": result,
            "explanation": f"{expression} = {result}"
        }
    except Exception as e:
        return {
            "operation": expression,
            "result": None,
            "explanation": f"è®¡ç®—é”™è¯¯: {str(e)}"
        }


class TestAdvancedFeatures(unittest.TestCase):
    """é«˜çº§åŠŸèƒ½æµ‹è¯•ç±»"""
    
    def get_advanced_model(self) -> ChatOpenAI:
        """
        åˆ›å»ºé…ç½®äº†é«˜çº§åŠŸèƒ½çš„ChatOpenAIå®ä¾‹
        
        Returns:
            ChatOpenAI: é…ç½®å¥½çš„é«˜çº§åŠŸèƒ½æ¨¡å‹å®ä¾‹
        """
        config = apis["local"]
        return ChatOpenAI(
            model="gpt-4o-mini",
            base_url=config["base_url"],
            api_key=config["api_key"],
            temperature=0.7,
            max_tokens=2000,
            timeout=60
        )
    
    def test_with_structured_output_pydantic(self) -> None:
        """
        æµ‹è¯•ä½¿ç”¨Pydanticç±»çš„with_structured_outputæ–¹æ³•
        """
        model = self.get_advanced_model()
        
        try:
            # æµ‹è¯•ç¬‘è¯ç”Ÿæˆ
            structured_llm = model.with_structured_output(Joke)
            response = structured_llm.invoke("Tell me a joke about cats")
            
            self.assertIsInstance(response, Joke)
            self.assertIsInstance(response.setup, str)
            self.assertIsInstance(response.punchline, str)
            self.assertTrue(len(response.setup) > 0)
            self.assertTrue(len(response.punchline) > 0)
            print(f"Pydantic structured output: {response}")
            
        except Exception as e:
            print(f"Pydantic structured output test failed: {e}")
    
    def test_with_structured_output_typeddict(self) -> None:
        """
        æµ‹è¯•ä½¿ç”¨TypedDictçš„with_structured_outputæ–¹æ³•
        """
        model = self.get_advanced_model()
        
        try:
            structured_llm = model.with_structured_output(JokeDict)
            response = structured_llm.invoke("Tell me a joke about dogs")
            
            self.assertIsInstance(response, dict)
            self.assertIn('setup', response)
            self.assertIn('punchline', response)
            self.assertIsInstance(response['setup'], str)
            self.assertIsInstance(response['punchline'], str)
            print(f"TypedDict structured output: {response}")
            
        except Exception as e:
            print(f"TypedDict structured output test failed: {e}")
    
    def test_with_structured_output_json_schema(self) -> None:
        """
        æµ‹è¯•ä½¿ç”¨JSON Schemaçš„with_structured_outputæ–¹æ³•
        """
        model = self.get_advanced_model()
        
        json_schema = {
            "title": "joke",
            "description": "Joke to tell user.",
            "type": "object",
            "properties": {
                "setup": {
                    "type": "string",
                    "description": "The setup of the joke",
                },
                "punchline": {
                    "type": "string",
                    "description": "The punchline to the joke",
                },
                "rating": {
                    "type": "integer",
                    "description": "How funny the joke is, from 1 to 10",
                    "default": None,
                },
            },
            "required": ["setup", "punchline"],
        }
        
        try:
            structured_llm = model.with_structured_output(json_schema)
            response = structured_llm.invoke("Tell me a joke about birds")
            
            self.assertIsInstance(response, dict)
            self.assertIn('setup', response)
            self.assertIn('punchline', response)
            print(f"JSON Schema structured output: {response}")
            
        except Exception as e:
            print(f"JSON Schema structured output test failed: {e}")
    
    def test_union_type_selection(self) -> None:
        """
        æµ‹è¯•Unionç±»å‹çš„å¤šæ¨¡å¼é€‰æ‹©
        """
        model = self.get_advanced_model()
        
        try:
            structured_llm = model.with_structured_output(MultiResponse)
            
            # æµ‹è¯•ç¬‘è¯è¯·æ±‚
            joke_response = structured_llm.invoke("Tell me a joke")
            self.assertIsInstance(joke_response, MultiResponse)
            print(f"Union type joke response: {joke_response}")
            
            # æµ‹è¯•å¯¹è¯è¯·æ±‚
            chat_response = structured_llm.invoke("How are you today?")
            self.assertIsInstance(chat_response, MultiResponse)
            print(f"Union type chat response: {chat_response}")
            
        except Exception as e:
            print(f"Union type selection test failed: {e}")
    
    def test_streaming_structured_output(self) -> None:
        """
        æµ‹è¯•æµå¼ç»“æ„åŒ–è¾“å‡º
        """
        model = self.get_advanced_model()
        
        try:
            structured_llm = model.with_structured_output(JokeDict)
            
            chunks = []
            for chunk in structured_llm.stream("Tell me a joke about programming"):
                chunks.append(chunk)
                print(f"Stream chunk: {chunk}")
            
            # éªŒè¯æœ€åä¸€ä¸ªchunkåŒ…å«å®Œæ•´ä¿¡æ¯
            final_chunk = chunks[-1] if chunks else {}
            self.assertIsInstance(final_chunk, dict)
            if 'setup' in final_chunk and 'punchline' in final_chunk:
                self.assertIsInstance(final_chunk['setup'], str)
                self.assertIsInstance(final_chunk['punchline'], str)
            
        except Exception as e:
            print(f"Streaming structured output test failed: {e}")
    
    def test_few_shot_prompting(self) -> None:
        """
        æµ‹è¯•Few-shot prompting
        """
        model = self.get_advanced_model()
        
        # ä½¿ç”¨ç³»ç»Ÿæ¶ˆæ¯çš„few-shotç¤ºä¾‹
        system = """You are a hilarious comedian. Your specialty is knock-knock jokes. \
Return a joke which has the setup and the final punchline.

Here are some examples of jokes:

example_user: Tell me a joke about planes
example_assistant: {"setup": "Why don't planes ever get tired?", "punchline": "Because they have rest wings!", "rating": 2}

example_user: Tell me another joke about planes  
example_assistant: {"setup": "Cargo", "punchline": "Cargo 'vroom vroom', but planes go 'zoom zoom'!", "rating": 10}"""

        prompt = ChatPromptTemplate.from_messages([
            ("system", system), 
            ("human", "{input}")
        ])
        
        try:
            structured_llm = model.with_structured_output(JokeDict)
            few_shot_chain = prompt | structured_llm
            
            response = few_shot_chain.invoke({"input": "what's something funny about woodpeckers"})
            
            self.assertIsInstance(response, dict)
            self.assertIn('setup', response)
            self.assertIn('punchline', response)
            print(f"Few-shot prompting response: {response}")
            
        except Exception as e:
            print(f"Few-shot prompting test failed: {e}")
    
    def test_pydantic_output_parser(self) -> None:
        """
        æµ‹è¯•PydanticOutputParser
        """
        model = self.get_advanced_model()
        
        # è®¾ç½®è§£æå™¨
        parser = PydanticOutputParser(pydantic_object=People)
        
        # åˆ›å»ºæç¤ºæ¨¡æ¿
        prompt = ChatPromptTemplate.from_messages([
            ("system", "Answer the user query. Wrap the output in `json` tags\n{format_instructions}"),
            ("human", "{query}")
        ]).partial(format_instructions=parser.get_format_instructions())
        
        try:
            chain = prompt | model | parser
            
            query = "Anna is 23 years old and she is 6 feet tall"
            response = chain.invoke({"query": query})
            
            self.assertIsInstance(response, People)
            self.assertGreater(len(response.people), 0)
            self.assertIsInstance(response.people[0], Person)
            print(f"PydanticOutputParser response: {response}")
            
        except Exception as e:
            print(f"PydanticOutputParser test failed: {e}")
    
    def test_custom_parsing(self) -> None:
        """
        æµ‹è¯•è‡ªå®šä¹‰è§£æ
        """
        model = self.get_advanced_model()
        
        # è‡ªå®šä¹‰è§£æå‡½æ•°
        def extract_json(message: AIMessage) -> List[dict]:
            """ä»æ¶ˆæ¯ä¸­æå–JSONå†…å®¹"""
            text = message.content
            pattern = r"```json(.*?)```"
            matches = re.findall(pattern, text, re.DOTALL)
            
            try:
                return [json.loads(match.strip()) for match in matches]
            except Exception:
                raise ValueError(f"Failed to parse: {message}")
        
        # åˆ›å»ºæç¤ºæ¨¡æ¿
        prompt = ChatPromptTemplate.from_messages([
            ("system", "Answer the user query. Output your answer as JSON that matches the given schema: ```json\n{schema}\n```. Make sure to wrap the answer in ```json and ``` tags"),
            ("human", "{query}")
        ]).partial(schema=People.schema())
        
        try:
            chain = prompt | model | extract_json
            
            query = "Bob is 30 years old and he is 5.8 feet tall"
            response = chain.invoke({"query": query})
            
            self.assertIsInstance(response, list)
            self.assertGreater(len(response), 0)
            self.assertIsInstance(response[0], dict)
            print(f"Custom parsing response: {response}")
            
        except Exception as e:
            print(f"Custom parsing test failed: {e}")
    
    def test_json_mode(self) -> None:
        """
        æµ‹è¯•JSONæ¨¡å¼
        """
        model = self.get_advanced_model()
        
        try:
            # æ³¨æ„ï¼šéœ€è¦æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒJSONæ¨¡å¼
            structured_llm = model.with_structured_output(None, method="json_mode")
            
            response = structured_llm.invoke(
                "Tell me a joke about cats, respond in JSON with `setup` and `punchline` keys"
            )
            
            self.assertIsInstance(response, dict)
            print(f"JSON mode response: {response}")
            
        except Exception as e:
            print(f"JSON mode test failed (may not be supported): {e}")
    
    def test_raw_output_handling(self) -> None:
        """
        æµ‹è¯•åŸå§‹è¾“å‡ºå¤„ç†
        """
        model = self.get_advanced_model()
        
        try:
            structured_llm = model.with_structured_output(Joke, include_raw=True)
            
            response = structured_llm.invoke("Tell me a joke about computers")
            
            self.assertIsInstance(response, dict)
            self.assertIn('raw', response)
            self.assertIn('parsed', response)
            self.assertIn('parsing_error', response)
            
            # éªŒè¯åŸå§‹è¾“å‡º
            self.assertIsInstance(response['raw'], AIMessage)
            
            # éªŒè¯è§£æç»“æœ
            if response['parsing_error'] is None:
                self.assertIsInstance(response['parsed'], (Joke, dict))
            
            print(f"Raw output handling response keys: {response.keys()}")
            print(f"Parsing error: {response['parsing_error']}")
            
        except Exception as e:
            print(f"Raw output handling test failed: {e}")
    
    def test_tool_binding_and_calling(self) -> None:
        """
        æµ‹è¯•å·¥å…·ç»‘å®šå’Œè°ƒç”¨åŠŸèƒ½
        """
        model = self.get_advanced_model()
        tools = [get_weather, calculate_math]
        
        # ç»‘å®šå·¥å…·åˆ°æ¨¡å‹
        model_with_tools = model.bind_tools(tools)
        
        messages = [HumanMessage(content="What's the weather like in Beijing?")]
        
        try:
            response = model_with_tools.invoke(messages)
            
            self.assertIsInstance(response, AIMessage)
            print(f"Tool binding response: {response.content}")
            
            if hasattr(response, 'tool_calls') and response.tool_calls:
                print(f"Tool calls made: {response.tool_calls}")
                for tool_call in response.tool_calls:
                    print(f"Tool: {tool_call['name']}, Args: {tool_call['args']}")
        except Exception as e:
            print(f"Tool binding test failed: {e}")
    
    def test_multiple_tool_calls(self) -> None:
        """
        æµ‹è¯•å¤šä¸ªå·¥å…·åŒæ—¶è°ƒç”¨
        """
        model = self.get_advanced_model()
        tools = [get_weather, calculate_math]
        model_with_tools = model.bind_tools(tools)
        
        messages = [HumanMessage(content="What's 3 * 12? Also, what's the weather in Shanghai?")]
        
        try:
            response = model_with_tools.invoke(messages)
            
            self.assertIsInstance(response, AIMessage)
            print(f"Multiple tools response: {response.content}")
            
            if hasattr(response, 'tool_calls') and response.tool_calls:
                print(f"Multiple tool calls: {len(response.tool_calls)} calls made")
                for i, tool_call in enumerate(response.tool_calls):
                    print(f"Tool {i+1}: {tool_call['name']}, Args: {tool_call['args']}")
        except Exception as e:
            print(f"Multiple tool calls test failed: {e}")
    
    def test_pydantic_tools_parser(self) -> None:
        """
        æµ‹è¯•Pydanticå·¥å…·è§£æå™¨
        """
        # åˆ›å»ºè§£æå™¨
        parser = PydanticToolsParser(tools=[MathResult, WeatherInfo])
        
        # æ¨¡æ‹Ÿå·¥å…·è°ƒç”¨æ•°æ®
        mock_tool_calls = [
            MathResult(operation="2+3", result=5, explanation="2+3 = 5"),
            WeatherInfo(location="åŒ—äº¬", temperature=25.0, humidity=60, description="æ™´æœ—")
        ]
        
        # éªŒè¯è§£æå™¨èƒ½æ­£ç¡®å¤„ç†å·¥å…·æ•°æ®
        self.assertEqual(len(mock_tool_calls), 2)
        self.assertIsInstance(mock_tool_calls[0], MathResult)
        self.assertIsInstance(mock_tool_calls[1], WeatherInfo)
        print("Pydantic tools parser test passed")
    
    def test_structured_output_with_pydantic(self) -> None:
        """
        æµ‹è¯•ä½¿ç”¨Pydanticæ¨¡å‹çš„ç»“æ„åŒ–è¾“å‡º
        """
        model = self.get_advanced_model()
        
        # æ„é€ ç³»ç»Ÿæ¶ˆæ¯ï¼Œè¦æ±‚è¿”å›ç‰¹å®šæ ¼å¼çš„JSON
        system_message = SystemMessage(content="""
        ä½ æ˜¯ä¸€ä¸ªå¤©æ°”åŠ©æ‰‹ã€‚è¯·ä»¥JSONæ ¼å¼è¿”å›å¤©æ°”ä¿¡æ¯ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
        - location: åœ°ç‚¹åç§°
        - temperature: æ¸©åº¦ï¼ˆæ‘„æ°åº¦ï¼‰
        - humidity: æ¹¿åº¦ç™¾åˆ†æ¯”
        - description: å¤©æ°”æè¿°
        """)
        
        user_message = HumanMessage(content="åŒ—äº¬ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
        
        try:
            response = model.invoke([system_message, user_message])
            
            self.assertIsInstance(response, AIMessage)
            print(f"Structured output response: {response.content}")
            
            # å°è¯•è§£æä¸ºJSON
            try:
                weather_data = json.loads(response.content)
                weather_info = WeatherInfo(**weather_data)
                print(f"Parsed weather info: {weather_info}")
            except (json.JSONDecodeError, ValueError) as e:
                print(f"JSON parsing failed: {e}")
        except Exception as e:
            print(f"Structured output test failed: {e}")
    
    def test_multi_turn_conversation_with_context(self) -> None:
        """
        æµ‹è¯•å¤šè½®å¯¹è¯ä¸­çš„ä¸Šä¸‹æ–‡ä¿æŒ
        """
        model = self.get_advanced_model()
        
        # ç¬¬ä¸€è½®å¯¹è¯
        conversation = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ï¼Œè®°ä½ç”¨æˆ·çš„åå¥½ã€‚"),
            HumanMessage(content="æˆ‘å–œæ¬¢è“è‰²ï¼Œè¿™æ˜¯æˆ‘æœ€å–œæ¬¢çš„é¢œè‰²ã€‚")
        ]
        
        try:
            # ç¬¬ä¸€æ¬¡è°ƒç”¨
            response1 = model.invoke(conversation)
            conversation.append(response1)
            conversation.append(HumanMessage(content="æ ¹æ®æˆ‘çš„å–œå¥½ï¼Œæ¨èä¸€ç§é¢œè‰²æ­é…ã€‚"))
            
            # ç¬¬äºŒæ¬¡è°ƒç”¨
            response2 = model.invoke(conversation)
            
            self.assertIsInstance(response2, AIMessage)
            print(f"Context preservation response: {response2.content}")
        except Exception as e:
            print(f"Multi-turn conversation test failed: {e}")
    
    def test_batch_processing(self) -> None:
        """
        æµ‹è¯•æ‰¹å¤„ç†åŠŸèƒ½
        """
        model = self.get_advanced_model()
        
        # å‡†å¤‡æ‰¹é‡è¯·æ±‚
        batch_requests = [
            [HumanMessage(content="Hello, how are you?")],
            [HumanMessage(content="What's 2+2?")],
            [HumanMessage(content="Tell me a joke.")]
        ]
        
        try:
            batch_responses = model.batch(batch_requests)
            
            self.assertEqual(len(batch_responses), 3)
            for i, response in enumerate(batch_responses):
                self.assertIsInstance(response, AIMessage)
                print(f"Batch response {i+1}: {response.content}")
        except Exception as e:
            print(f"Batch processing test failed: {e}")
    
    def test_tool_execution(self) -> None:
        """
        æµ‹è¯•å®é™…å·¥å…·æ‰§è¡Œ
        """
        # æµ‹è¯•æ•°å­¦è®¡ç®—å·¥å…·
        math_result = calculate_math("15 + 27")
        self.assertEqual(math_result["result"], 42)
        self.assertEqual(math_result["operation"], "15 + 27")
        print(f"Math tool result: {math_result}")
        
        # æµ‹è¯•å¤©æ°”æŸ¥è¯¢å·¥å…·
        weather_result = get_weather("åŒ—äº¬")
        self.assertEqual(weather_result["location"], "åŒ—äº¬")
        self.assertIsInstance(weather_result["temperature"], float)
        self.assertIsInstance(weather_result["humidity"], int)
        print(f"Weather tool result: {weather_result}")
    
    def test_temperature_and_creativity_effects(self) -> None:
        """
        æµ‹è¯•temperatureå‚æ•°å¯¹åˆ›é€ æ€§çš„å½±å“
        """
        config = apis["local"]
        
        # ä½temperatureæ¨¡å‹ï¼ˆä¿å®ˆï¼‰
        conservative_model = ChatOpenAI(
            model="gpt-4o-mini",
            base_url=config["base_url"],
            api_key=config["api_key"],
            temperature=0.1
        )
        
        # é«˜temperatureæ¨¡å‹ï¼ˆåˆ›é€ æ€§ï¼‰
        creative_model = ChatOpenAI(
            model="gpt-4o-mini",
            base_url=config["base_url"],
            api_key=config["api_key"],
            temperature=0.9
        )
        
        # éªŒè¯é…ç½®å·®å¼‚
        self.assertEqual(conservative_model.temperature, 0.1)
        self.assertEqual(creative_model.temperature, 0.9)
        
        # æµ‹è¯•å®é™…æ•ˆæœ
        messages = [HumanMessage(content="å†™ä¸€ä¸ªå…³äºæ˜¥å¤©çš„çŸ­å¥")]
        
        try:
            conservative_response = conservative_model.invoke(messages)
            creative_response = creative_model.invoke(messages)
            
            print(f"Conservative (T=0.1): {conservative_response.content}")
            print(f"Creative (T=0.9): {creative_response.content}")
        except Exception as e:
            print(f"Temperature effects test failed: {e}")


def main() -> int:
    """
    è¿è¡Œé«˜çº§åŠŸèƒ½æµ‹è¯•çš„ä¸»å‡½æ•°
    
    Returns:
        int: é€€å‡ºç ï¼Œ0è¡¨ç¤ºæˆåŠŸ
    """
    print("ğŸš€ è¿è¡Œé«˜çº§åŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    # è¿è¡Œæµ‹è¯•
    unittest.main(verbosity=2)
    return 0


if __name__ == "__main__":
    main()