"""
é«˜çº§åŠŸèƒ½æµ‹è¯•

æµ‹è¯•ChatOpenAIæ¨¡å‹çš„é«˜çº§åŠŸèƒ½ï¼ŒåŒ…æ‹¬å·¥å…·è°ƒç”¨ã€ç»“æ„åŒ–è¾“å‡ºã€æ‰¹å¤„ç†ç­‰
"""

import unittest
import json
from typing import List, Dict, Any, Optional
from pydantic import BaseModel, Field

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage
from langchain_core.tools import tool
from langchain_core.output_parsers import PydanticToolsParser

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../../src'))

from src.config.api import apis


# å®šä¹‰æµ‹è¯•ç”¨çš„Pydanticæ¨¡å‹
class WeatherInfo(BaseModel):
    """å¤©æ°”ä¿¡æ¯æ¨¡å‹"""
    location: str = Field(description="åœ°ç‚¹åç§°")
    temperature: float = Field(description="æ¸©åº¦ï¼ˆæ‘„æ°åº¦ï¼‰")
    humidity: int = Field(description="æ¹¿åº¦ç™¾åˆ†æ¯”")
    description: str = Field(description="å¤©æ°”æè¿°")


class MathResult(BaseModel):
    """æ•°å­¦è®¡ç®—ç»“æœæ¨¡å‹"""
    operation: str = Field(description="æ‰§è¡Œçš„æ•°å­¦è¿ç®—")
    result: float = Field(description="è®¡ç®—ç»“æœ")
    explanation: str = Field(description="è®¡ç®—è¿‡ç¨‹è¯´æ˜")


# å®šä¹‰æµ‹è¯•ç”¨çš„å·¥å…·
@tool
def get_weather(location: str) -> Dict[str, Any]:
    """
    è·å–æŒ‡å®šåœ°ç‚¹çš„å¤©æ°”ä¿¡æ¯
    
    Args:
        location: åœ°ç‚¹åç§°
        
    Returns:
        Dict[str, Any]: å¤©æ°”ä¿¡æ¯å­—å…¸
    """
    return {
        "location": location,
        "temperature": 22.5,
        "humidity": 65,
        "description": "æ™´æœ—"
    }


@tool  
def calculate_math(expression: str) -> Dict[str, Any]:
    """
    è®¡ç®—æ•°å­¦è¡¨è¾¾å¼
    
    Args:
        expression: æ•°å­¦è¡¨è¾¾å¼å­—ç¬¦ä¸²
        
    Returns:
        Dict[str, Any]: è®¡ç®—ç»“æœå­—å…¸
    """
    try:
        result = eval(expression)  # ä»…ç”¨äºæµ‹è¯•ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦å®‰å…¨çš„æ•°å­¦è§£æå™¨
        return {
            "operation": expression,
            "result": result,
            "explanation": f"{expression} = {result}"
        }
    except Exception as e:
        return {
            "operation": expression,
            "result": None,
            "explanation": f"è®¡ç®—é”™è¯¯: {str(e)}"
        }


class TestAdvancedFeatures(unittest.TestCase):
    """é«˜çº§åŠŸèƒ½æµ‹è¯•ç±»"""
    
    def get_advanced_model(self) -> ChatOpenAI:
        """
        åˆ›å»ºé…ç½®äº†é«˜çº§åŠŸèƒ½çš„ChatOpenAIå®ä¾‹
        
        Returns:
            ChatOpenAI: é…ç½®å¥½çš„é«˜çº§åŠŸèƒ½æ¨¡å‹å®ä¾‹
        """
        config = apis["local"]
        return ChatOpenAI(
            model="gpt-4o-mini",
            base_url=config["base_url"],
            api_key=config["api_key"],
            temperature=0.7,
            max_tokens=2000,
            timeout=60
        )
    
    def test_tool_binding_and_calling(self) -> None:
        """
        æµ‹è¯•å·¥å…·ç»‘å®šå’Œè°ƒç”¨åŠŸèƒ½
        """
        model = self.get_advanced_model()
        tools = [get_weather, calculate_math]
        
        # ç»‘å®šå·¥å…·åˆ°æ¨¡å‹
        model_with_tools = model.bind_tools(tools)
        
        messages = [HumanMessage(content="What's the weather like in Beijing?")]
        
        try:
            response = model_with_tools.invoke(messages)
            
            self.assertIsInstance(response, AIMessage)
            print(f"Tool binding response: {response.content}")
            
            if hasattr(response, 'tool_calls') and response.tool_calls:
                print(f"Tool calls made: {response.tool_calls}")
                for tool_call in response.tool_calls:
                    print(f"Tool: {tool_call['name']}, Args: {tool_call['args']}")
        except Exception as e:
            print(f"Tool binding test failed: {e}")
    
    def test_multiple_tool_calls(self) -> None:
        """
        æµ‹è¯•å¤šä¸ªå·¥å…·åŒæ—¶è°ƒç”¨
        """
        model = self.get_advanced_model()
        tools = [get_weather, calculate_math]
        model_with_tools = model.bind_tools(tools)
        
        messages = [HumanMessage(content="What's 3 * 12? Also, what's the weather in Shanghai?")]
        
        try:
            response = model_with_tools.invoke(messages)
            
            self.assertIsInstance(response, AIMessage)
            print(f"Multiple tools response: {response.content}")
            
            if hasattr(response, 'tool_calls') and response.tool_calls:
                print(f"Multiple tool calls: {len(response.tool_calls)} calls made")
                for i, tool_call in enumerate(response.tool_calls):
                    print(f"Tool {i+1}: {tool_call['name']}, Args: {tool_call['args']}")
        except Exception as e:
            print(f"Multiple tool calls test failed: {e}")
    
    def test_pydantic_tools_parser(self) -> None:
        """
        æµ‹è¯•Pydanticå·¥å…·è§£æå™¨
        """
        # åˆ›å»ºè§£æå™¨
        parser = PydanticToolsParser(tools=[MathResult, WeatherInfo])
        
        # æ¨¡æ‹Ÿå·¥å…·è°ƒç”¨æ•°æ®
        mock_tool_calls = [
            MathResult(operation="2+3", result=5, explanation="2+3 = 5"),
            WeatherInfo(location="åŒ—äº¬", temperature=25.0, humidity=60, description="æ™´æœ—")
        ]
        
        # éªŒè¯è§£æå™¨èƒ½æ­£ç¡®å¤„ç†å·¥å…·æ•°æ®
        self.assertEqual(len(mock_tool_calls), 2)
        self.assertIsInstance(mock_tool_calls[0], MathResult)
        self.assertIsInstance(mock_tool_calls[1], WeatherInfo)
        print("Pydantic tools parser test passed")
    
    def test_structured_output_with_pydantic(self) -> None:
        """
        æµ‹è¯•ä½¿ç”¨Pydanticæ¨¡å‹çš„ç»“æ„åŒ–è¾“å‡º
        """
        model = self.get_advanced_model()
        
        # æ„é€ ç³»ç»Ÿæ¶ˆæ¯ï¼Œè¦æ±‚è¿”å›ç‰¹å®šæ ¼å¼çš„JSON
        system_message = SystemMessage(content="""
        ä½ æ˜¯ä¸€ä¸ªå¤©æ°”åŠ©æ‰‹ã€‚è¯·ä»¥JSONæ ¼å¼è¿”å›å¤©æ°”ä¿¡æ¯ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
        - location: åœ°ç‚¹åç§°
        - temperature: æ¸©åº¦ï¼ˆæ‘„æ°åº¦ï¼‰
        - humidity: æ¹¿åº¦ç™¾åˆ†æ¯”
        - description: å¤©æ°”æè¿°
        """)
        
        user_message = HumanMessage(content="åŒ—äº¬ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
        
        try:
            response = model.invoke([system_message, user_message])
            
            self.assertIsInstance(response, AIMessage)
            print(f"Structured output response: {response.content}")
            
            # å°è¯•è§£æä¸ºJSON
            try:
                weather_data = json.loads(response.content)
                weather_info = WeatherInfo(**weather_data)
                print(f"Parsed weather info: {weather_info}")
            except (json.JSONDecodeError, ValueError) as e:
                print(f"JSON parsing failed: {e}")
        except Exception as e:
            print(f"Structured output test failed: {e}")
    
    def test_multi_turn_conversation_with_context(self) -> None:
        """
        æµ‹è¯•å¤šè½®å¯¹è¯ä¸­çš„ä¸Šä¸‹æ–‡ä¿æŒ
        """
        model = self.get_advanced_model()
        
        # ç¬¬ä¸€è½®å¯¹è¯
        conversation = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ï¼Œè®°ä½ç”¨æˆ·çš„åå¥½ã€‚"),
            HumanMessage(content="æˆ‘å–œæ¬¢è“è‰²ï¼Œè¿™æ˜¯æˆ‘æœ€å–œæ¬¢çš„é¢œè‰²ã€‚")
        ]
        
        try:
            # ç¬¬ä¸€æ¬¡è°ƒç”¨
            response1 = model.invoke(conversation)
            conversation.append(response1)
            conversation.append(HumanMessage(content="æ ¹æ®æˆ‘çš„å–œå¥½ï¼Œæ¨èä¸€ç§é¢œè‰²æ­é…ã€‚"))
            
            # ç¬¬äºŒæ¬¡è°ƒç”¨
            response2 = model.invoke(conversation)
            
            self.assertIsInstance(response2, AIMessage)
            print(f"Context preservation response: {response2.content}")
        except Exception as e:
            print(f"Multi-turn conversation test failed: {e}")
    
    def test_batch_processing(self) -> None:
        """
        æµ‹è¯•æ‰¹å¤„ç†åŠŸèƒ½
        """
        model = self.get_advanced_model()
        
        # å‡†å¤‡æ‰¹é‡è¯·æ±‚
        batch_requests = [
            [HumanMessage(content="Hello, how are you?")],
            [HumanMessage(content="What's 2+2?")],
            [HumanMessage(content="Tell me a joke.")]
        ]
        
        try:
            batch_responses = model.batch(batch_requests)
            
            self.assertEqual(len(batch_responses), 3)
            for i, response in enumerate(batch_responses):
                self.assertIsInstance(response, AIMessage)
                print(f"Batch response {i+1}: {response.content}")
        except Exception as e:
            print(f"Batch processing test failed: {e}")
    
    def test_tool_execution(self) -> None:
        """
        æµ‹è¯•å®é™…å·¥å…·æ‰§è¡Œ
        """
        # æµ‹è¯•æ•°å­¦è®¡ç®—å·¥å…·
        math_result = calculate_math("15 + 27")
        self.assertEqual(math_result["result"], 42)
        self.assertEqual(math_result["operation"], "15 + 27")
        print(f"Math tool result: {math_result}")
        
        # æµ‹è¯•å¤©æ°”æŸ¥è¯¢å·¥å…·
        weather_result = get_weather("åŒ—äº¬")
        self.assertEqual(weather_result["location"], "åŒ—äº¬")
        self.assertIsInstance(weather_result["temperature"], float)
        self.assertIsInstance(weather_result["humidity"], int)
        print(f"Weather tool result: {weather_result}")
    
    def test_temperature_and_creativity_effects(self) -> None:
        """
        æµ‹è¯•temperatureå‚æ•°å¯¹åˆ›é€ æ€§çš„å½±å“
        """
        config = apis["local"]
        
        # ä½temperatureæ¨¡å‹ï¼ˆä¿å®ˆï¼‰
        conservative_model = ChatOpenAI(
            model="gpt-4o-mini",
            base_url=config["base_url"],
            api_key=config["api_key"],
            temperature=0.1
        )
        
        # é«˜temperatureæ¨¡å‹ï¼ˆåˆ›é€ æ€§ï¼‰
        creative_model = ChatOpenAI(
            model="gpt-4o-mini",
            base_url=config["base_url"],
            api_key=config["api_key"],
            temperature=0.9
        )
        
        # éªŒè¯é…ç½®å·®å¼‚
        self.assertEqual(conservative_model.temperature, 0.1)
        self.assertEqual(creative_model.temperature, 0.9)
        
        # æµ‹è¯•å®é™…æ•ˆæœ
        messages = [HumanMessage(content="å†™ä¸€ä¸ªå…³äºæ˜¥å¤©çš„çŸ­å¥")]
        
        try:
            conservative_response = conservative_model.invoke(messages)
            creative_response = creative_model.invoke(messages)
            
            print(f"Conservative (T=0.1): {conservative_response.content}")
            print(f"Creative (T=0.9): {creative_response.content}")
        except Exception as e:
            print(f"Temperature effects test failed: {e}")


def main() -> int:
    """
    è¿è¡Œé«˜çº§åŠŸèƒ½æµ‹è¯•çš„ä¸»å‡½æ•°
    
    Returns:
        int: é€€å‡ºç ï¼Œ0è¡¨ç¤ºæˆåŠŸ
    """
    print("ğŸš€ è¿è¡Œé«˜çº§åŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    # è¿è¡Œæµ‹è¯•
    unittest.main(verbosity=2)
    return 0


if __name__ == "__main__":
    main()