"""
é”™è¯¯å¤„ç†æµ‹è¯•

æµ‹è¯•ChatOpenAIæ¨¡å‹çš„é”™è¯¯å¤„ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬ç½‘ç»œé”™è¯¯ã€APIé”™è¯¯ã€å‚æ•°é”™è¯¯ç­‰
"""

import unittest
from typing import Dict, Any
import requests

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../../src'))

from src.config.api import apis


class TestErrorHandling(unittest.TestCase):
    """é”™è¯¯å¤„ç†æµ‹è¯•ç±»"""
    
    def get_chat_model(self) -> ChatOpenAI:
        """
        åˆ›å»ºChatOpenAIå®ä¾‹ç”¨äºé”™è¯¯æµ‹è¯•
        
        Returns:
            ChatOpenAI: é…ç½®å¥½çš„èŠå¤©æ¨¡å‹å®ä¾‹
        """
        config = apis["local"]
        return ChatOpenAI(
            model="gpt-4o-mini",
            base_url=config["base_url"],
            api_key=config["api_key"],
            temperature=0.7,
            max_tokens=1000,
            timeout=30
        )
    
    def test_connection_error(self) -> None:
        """
        æµ‹è¯•è¿æ¥é”™è¯¯å¤„ç†
        """
        config = apis["local"]
        
        # ä½¿ç”¨æ— æ•ˆçš„URL
        invalid_model = ChatOpenAI(
            model="gpt-4o-mini",
            base_url="http://invalid-url-that-does-not-exist:9999",
            api_key=config["api_key"],
            timeout=5
        )
        
        messages = [HumanMessage(content="Hello")]
        
        try:
            response = invalid_model.invoke(messages)
            print("Unexpected: Connection should have failed")
        except Exception as e:
            print(f"Expected connection error: {type(e).__name__}: {e}")
            # è¿™æ˜¯é¢„æœŸçš„é”™è¯¯
    
    def test_invalid_api_key_error(self) -> None:
        """
        æµ‹è¯•æ— æ•ˆAPIå¯†é’¥é”™è¯¯å¤„ç†
        """
        config = apis["local"]
        
        # ä½¿ç”¨æ— æ•ˆçš„APIå¯†é’¥
        invalid_key_model = ChatOpenAI(
            model="gpt-4o-mini",
            base_url=config["base_url"],
            api_key="invalid-api-key-12345",
            timeout=30
        )
        
        messages = [HumanMessage(content="Hello")]
        
        try:
            response = invalid_key_model.invoke(messages)
            print("Unexpected: Invalid API key should have failed")
        except Exception as e:
            print(f"Expected authentication error: {type(e).__name__}: {e}")
            # è¿™æ˜¯é¢„æœŸçš„é”™è¯¯
    
    def test_timeout_error(self) -> None:
        """
        æµ‹è¯•è¶…æ—¶é”™è¯¯å¤„ç†
        """
        config = apis["local"]
        
        # è®¾ç½®æçŸ­çš„è¶…æ—¶æ—¶é—´
        timeout_model = ChatOpenAI(
            model="gpt-4o-mini",
            base_url=config["base_url"],
            api_key=config["api_key"],
            timeout=0.001  # æçŸ­è¶…æ—¶
        )
        
        messages = [HumanMessage(content="Write a long story")]
        
        try:
            response = timeout_model.invoke(messages)
            print("Unexpected: Timeout should have occurred")
        except Exception as e:
            print(f"Expected timeout error: {type(e).__name__}: {e}")
            # è¿™æ˜¯é¢„æœŸçš„é”™è¯¯
    
    def test_context_length_exceeded_error(self) -> None:
        """
        æµ‹è¯•ä¸Šä¸‹æ–‡é•¿åº¦è¶…é™é”™è¯¯å¤„ç†
        """
        chat_model = self.get_chat_model()
        
        # åˆ›å»ºä¸€ä¸ªè¶…é•¿çš„æ¶ˆæ¯
        very_long_content = "This is a very long message. " * 10000
        messages = [HumanMessage(content=very_long_content)]
        
        try:
            response = chat_model.invoke(messages)
            print("Unexpected: Context length should have been exceeded")
        except Exception as e:
            print(f"Expected context length error: {type(e).__name__}: {e}")
            # è¿™æ˜¯é¢„æœŸçš„é”™è¯¯
    
    def test_streaming_interruption_error(self) -> None:
        """
        æµ‹è¯•æµå¼è¾“å‡ºä¸­æ–­é”™è¯¯å¤„ç†
        """
        config = apis["local"]
        streaming_model = ChatOpenAI(
            model="gpt-4o-mini",
            base_url=config["base_url"],
            api_key=config["api_key"],
            streaming=True,
            timeout=1  # çŸ­è¶…æ—¶
        )
        
        messages = [HumanMessage(content="Write a very long detailed story")]
        
        try:
            chunks = []
            for chunk in streaming_model.stream(messages):
                chunks.append(chunk)
                # äººä¸ºä¸­æ–­æµ‹è¯•
                if len(chunks) > 5:
                    break
            
            print(f"Streaming collected {len(chunks)} chunks before interruption")
        except Exception as e:
            print(f"Streaming interruption: {type(e).__name__}: {e}")
    
    def test_batch_error_handling(self) -> None:
        """
        æµ‹è¯•æ‰¹å¤„ç†é”™è¯¯å¤„ç†
        """
        chat_model = self.get_chat_model()
        
        # åŒ…å«æœ‰æ•ˆå’Œæ— æ•ˆè¯·æ±‚çš„æ‰¹å¤„ç†
        message_batches = [
            [HumanMessage(content="Hello 1")],
            [],  # æ— æ•ˆçš„ç©ºæ¶ˆæ¯
            [HumanMessage(content="Hello 3")]
        ]
        
        try:
            responses = chat_model.batch(message_batches)
            print("Unexpected: Batch with invalid request should have failed")
        except Exception as e:
            print(f"Expected batch error: {type(e).__name__}: {e}")
    
    def test_invalid_base_url(self) -> None:
        """
        æµ‹è¯•æ— æ•ˆçš„base_urlå¤„ç†
        """
        config = apis["local"]
        
        # æµ‹è¯•æ ¼å¼é”™è¯¯çš„URL
        try:
            ChatOpenAI(
                model="gpt-4o-mini",
                base_url="invalid-url-format",
                api_key=config["api_key"]
            )
        except Exception as e:
            print(f"Invalid base URL error: {type(e).__name__}: {e}")
    
    def test_empty_api_key(self) -> None:
        """
        æµ‹è¯•ç©ºAPIå¯†é’¥å¤„ç†
        """
        config = apis["local"]
        
        # æµ‹è¯•ç©ºAPIå¯†é’¥
        try:
            ChatOpenAI(
                model="gpt-4o-mini",
                base_url=config["base_url"],
                api_key="",  # ç©ºå¯†é’¥
                temperature=0.7
            )
        except Exception as e:
            print(f"Empty API key error: {type(e).__name__}: {e}")
    
    def test_network_resilience(self) -> None:
        """
        æµ‹è¯•ç½‘ç»œéŸ§æ€§
        """
        chat_model = self.get_chat_model()
        messages = [HumanMessage(content="Test network resilience")]
        
        try:
            # æ­£å¸¸è°ƒç”¨åº”è¯¥å·¥ä½œ
            response = chat_model.invoke(messages)
            self.assertIsInstance(response, AIMessage)
            print(f"Network resilience test - Normal call successful: {response.content}")
            
        except Exception as e:
            print(f"Network resilience test failed: {type(e).__name__}: {e}")
    
    def test_error_recovery(self) -> None:
        """
        æµ‹è¯•é”™è¯¯æ¢å¤
        """
        config = apis["local"]
        
        # å…ˆç”¨é”™è¯¯é…ç½®
        try:
            bad_model = ChatOpenAI(
                model="gpt-4o-mini",
                base_url="http://invalid-url:9999",
                api_key=config["api_key"],
                timeout=1
            )
            bad_model.invoke([HumanMessage(content="This should fail")])
        except Exception as e:
            print(f"Expected error with bad config: {type(e).__name__}")
        
        # ç„¶åç”¨æ­£ç¡®é…ç½®
        try:
            good_model = self.get_chat_model()
            response = good_model.invoke([HumanMessage(content="This should work")])
            print(f"Recovery successful: {response.content}")
        except Exception as e:
            print(f"Recovery failed: {type(e).__name__}: {e}")


def main() -> int:
    """
    è¿è¡Œé”™è¯¯å¤„ç†æµ‹è¯•çš„ä¸»å‡½æ•°
    
    Returns:
        int: é€€å‡ºç ï¼Œ0è¡¨ç¤ºæˆåŠŸ
    """
    print("ğŸš€ è¿è¡Œé”™è¯¯å¤„ç†æµ‹è¯•")
    print("=" * 50)
    
    # è¿è¡Œæµ‹è¯•
    unittest.main(verbosity=2)
    return 0


if __name__ == "__main__":
    main()