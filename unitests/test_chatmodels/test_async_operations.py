"""
å¼‚æ­¥æ“ä½œæµ‹è¯•

æµ‹è¯•ChatOpenAIæ¨¡å‹çš„å¼‚æ­¥åŠŸèƒ½ï¼ŒåŒ…æ‹¬å¼‚æ­¥è°ƒç”¨å’Œå¼‚æ­¥æµå¼è¾“å‡º
"""

import unittest
import asyncio
from typing import List

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.outputs import ChatGenerationChunk

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../../src'))

from src.config.api import apis


class TestAsyncChat(unittest.TestCase):
    """å¼‚æ­¥èŠå¤©æµ‹è¯•ç±»"""
    
    def get_async_chat_model(self) -> ChatOpenAI:
        """
        åˆ›å»ºç”¨äºå¼‚æ­¥æ“ä½œçš„ChatOpenAIå®ä¾‹
        
        Returns:
            ChatOpenAI: é…ç½®å¥½çš„å¼‚æ­¥èŠå¤©æ¨¡å‹å®ä¾‹
        """
        config = apis["local"]
        return ChatOpenAI(
            model="gpt-4o-mini",
            base_url=config["base_url"],
            api_key=config["api_key"],
            temperature=0.7,
            max_tokens=1000,
            timeout=60
        )
    
    def test_basic_async_invoke(self) -> None:
        """
        æµ‹è¯•åŸºæœ¬å¼‚æ­¥è°ƒç”¨
        """
        async def run_test():
            async_model = self.get_async_chat_model()
            messages = [HumanMessage(content="Hello async world")]
            
            try:
                response = await async_model.ainvoke(messages)
                
                self.assertIsInstance(response, AIMessage)
                self.assertIn("Hello", response.content)
                print(f"Basic async response: {response.content}")
            except Exception as e:
                print(f"Basic async test failed: {e}")
        
        # è¿è¡Œå¼‚æ­¥æµ‹è¯•
        asyncio.run(run_test())
    
    def test_async_system_message(self) -> None:
        """
        æµ‹è¯•åŒ…å«ç³»ç»Ÿæ¶ˆæ¯çš„å¼‚æ­¥è°ƒç”¨
        """
        async def run_test():
            async_model = self.get_async_chat_model()
            messages = [
                SystemMessage(content="You are a helpful math assistant."),
                HumanMessage(content="What is 5 + 3?")
            ]
            
            try:
                response = await async_model.ainvoke(messages)
                
                self.assertIsInstance(response, AIMessage)
                print(f"Async system message response: {response.content}")
            except Exception as e:
                print(f"Async system message test failed: {e}")
        
        asyncio.run(run_test())
    
    def test_async_streaming(self) -> None:
        """
        æµ‹è¯•å¼‚æ­¥æµå¼è¾“å‡º
        """
        async def run_test():
            async_model = self.get_async_chat_model()
            messages = [HumanMessage(content="Count from 1 to 3")]
            
            try:
                chunks = []
                async for chunk in async_model.astream(messages):
                    chunks.append(chunk)
                    print(f"Async chunk: {chunk.content}")
                
                self.assertGreater(len(chunks), 0)
                full_response = "".join([chunk.content for chunk in chunks])
                print(f"Async streaming full response: {full_response}")
            except Exception as e:
                print(f"Async streaming test failed: {e}")
        
        asyncio.run(run_test())
    
    def test_async_batch_processing(self) -> None:
        """
        æµ‹è¯•å¼‚æ­¥æ‰¹å¤„ç†
        """
        async def run_test():
            async_model = self.get_async_chat_model()
            
            message_batches = [
                [HumanMessage(content="Hello 1")],
                [HumanMessage(content="Hello 2")],
                [HumanMessage(content="Hello 3")]
            ]
            
            try:
                results = await async_model.abatch(message_batches)
                
                self.assertEqual(len(results), 3)
                for i, result in enumerate(results):
                    self.assertIsInstance(result, AIMessage)
                    print(f"Async batch response {i+1}: {result.content}")
            except Exception as e:
                print(f"Async batch processing test failed: {e}")
        
        asyncio.run(run_test())
    
    def test_async_concurrent_requests(self) -> None:
        """
        æµ‹è¯•å¼‚æ­¥å¹¶å‘è¯·æ±‚
        """
        async def run_test():
            async_model = self.get_async_chat_model()
            
            # åˆ›å»ºå¤šä¸ªå¹¶å‘è¯·æ±‚
            concurrent_messages = [
                [HumanMessage(content=f"Request {i}")]
                for i in range(5)
            ]
            
            try:
                # å¹¶å‘æ‰§è¡Œ
                tasks = [async_model.ainvoke(msgs) for msgs in concurrent_messages]
                responses = await asyncio.gather(*tasks)
                
                self.assertEqual(len(responses), 5)
                
                for i, response in enumerate(responses):
                    self.assertIsInstance(response, AIMessage)
                    print(f"Concurrent response {i+1}: {response.content}")
                    
            except Exception as e:
                print(f"Async concurrent requests test failed: {e}")
        
        asyncio.run(run_test())
    
    def test_async_context_preservation(self) -> None:
        """
        æµ‹è¯•å¼‚æ­¥æ“ä½œä¸­çš„ä¸Šä¸‹æ–‡ä¿æŒ
        """
        async def run_test():
            async_model = self.get_async_chat_model()
            
            # ç¬¬ä¸€è½®å¯¹è¯
            conversation = [
                HumanMessage(content="My name is Alice")
            ]
            
            try:
                response1 = await async_model.ainvoke(conversation)
                
                # ç¬¬äºŒè½®å¯¹è¯
                conversation.extend([
                    response1,
                    HumanMessage(content="What's my name?")
                ])
                
                response2 = await async_model.ainvoke(conversation)
                
                self.assertIsInstance(response2, AIMessage)
                print(f"Async context preservation: {response2.content}")
            except Exception as e:
                print(f"Async context preservation test failed: {e}")
        
        asyncio.run(run_test())
    
    def test_async_performance_timing(self) -> None:
        """
        æµ‹è¯•å¼‚æ­¥æ“ä½œæ€§èƒ½è®¡æ—¶
        """
        async def run_test():
            async_model = self.get_async_chat_model()
            
            # å‡†å¤‡å¤šä¸ªè¯·æ±‚
            messages_list = [
                [HumanMessage(content=f"Performance test {i}")]
                for i in range(3)
            ]
            
            try:
                # å¹¶å‘æ‰§è¡Œ
                import time
                start_time = time.time()
                tasks = [async_model.ainvoke(msgs) for msgs in messages_list]
                await asyncio.gather(*tasks)
                end_time = time.time()
                
                concurrent_time = end_time - start_time
                
                # éªŒè¯å¹¶å‘æ‰§è¡Œæ—¶é—´åˆç†
                print(f"Async concurrent execution time: {concurrent_time:.2f} seconds")
                
                # é¡ºåºæ‰§è¡Œå¯¹æ¯”
                start_time = time.time()
                for msgs in messages_list:
                    await async_model.ainvoke(msgs)
                end_time = time.time()
                
                sequential_time = end_time - start_time
                print(f"Async sequential execution time: {sequential_time:.2f} seconds")
                
                # å¹¶å‘åº”è¯¥æ¯”é¡ºåºå¿«
                self.assertLess(concurrent_time, sequential_time * 0.8)
                
            except Exception as e:
                print(f"Async performance timing test failed: {e}")
        
        asyncio.run(run_test())
    
    def test_async_cancellation(self) -> None:
        """
        æµ‹è¯•å¼‚æ­¥æ“ä½œå–æ¶ˆ
        """
        async def run_test():
            async_model = self.get_async_chat_model()
            messages = [HumanMessage(content="Write a very long story")]
            
            try:
                # åˆ›å»ºä»»åŠ¡å¹¶å¿«é€Ÿå–æ¶ˆ
                task = asyncio.create_task(async_model.ainvoke(messages))
                await asyncio.sleep(0.1)  # è®©ä»»åŠ¡å¼€å§‹
                task.cancel()
                
                with self.assertRaises(asyncio.CancelledError):
                    await task
                    
                print("Async cancellation test passed")
            except Exception as e:
                print(f"Async cancellation test failed: {e}")
        
        asyncio.run(run_test())
    
    def test_async_model_configuration(self) -> None:
        """
        æµ‹è¯•å¼‚æ­¥æ¨¡å‹é…ç½®
        """
        config = apis["local"]
        
        async_model = ChatOpenAI(
            model="gpt-4o-mini",
            base_url=config["base_url"],
            api_key=config["api_key"],
            temperature=0.5,
            timeout=120
        )
        
        # éªŒè¯é…ç½®
        self.assertEqual(async_model.temperature, 0.5)
        self.assertEqual(async_model.request_timeout, 120)
        self.assertEqual(async_model.model_name, "gpt-4o-mini")
        print("Async model configuration test passed")
    
    def test_async_vs_sync_comparison(self) -> None:
        """
        æ¯”è¾ƒå¼‚æ­¥å’ŒåŒæ­¥è°ƒç”¨
        """
        async def run_test():
            config = apis["local"]
            
            # åˆ›å»ºæ¨¡å‹
            model = ChatOpenAI(
                model="gpt-4o-mini",
                base_url=config["base_url"],
                api_key=config["api_key"],
                temperature=0.7
            )
            
            messages = [HumanMessage(content="What is the capital of France?")]
            
            try:
                # å¼‚æ­¥è°ƒç”¨
                import time
                start_time = time.time()
                async_response = await model.ainvoke(messages)
                async_time = time.time() - start_time
                
                # åŒæ­¥è°ƒç”¨
                start_time = time.time()
                sync_response = model.invoke(messages)
                sync_time = time.time() - start_time
                
                print(f"Async response ({async_time:.2f}s): {async_response.content}")
                print(f"Sync response ({sync_time:.2f}s): {sync_response.content}")
                
                # éªŒè¯ä¸¤ç§æ–¹å¼éƒ½èƒ½å·¥ä½œ
                self.assertIsInstance(async_response, AIMessage)
                self.assertIsInstance(sync_response, AIMessage)
                
            except Exception as e:
                print(f"Async vs sync comparison test failed: {e}")
        
        asyncio.run(run_test())


def main() -> int:
    """
    è¿è¡Œå¼‚æ­¥æ“ä½œæµ‹è¯•çš„ä¸»å‡½æ•°
    
    Returns:
        int: é€€å‡ºç ï¼Œ0è¡¨ç¤ºæˆåŠŸ
    """
    print("ğŸš€ è¿è¡Œå¼‚æ­¥æ“ä½œæµ‹è¯•")
    print("=" * 50)
    
    # è¿è¡Œæµ‹è¯•
    unittest.main(verbosity=2)
    return 0


if __name__ == "__main__":
    main()